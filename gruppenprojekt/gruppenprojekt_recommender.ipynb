{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ffb10be",
   "metadata": {},
   "source": [
    "# Gruppenprojekt - Big Data Analysis\n",
    "Dieses Notebook beschreibt unser Programm und bietet einen Ãœberblik Ã¼ber unser Projekt mit den *FlixNet*â€‘Daten.\n",
    "\n",
    "***INFO**: Dieses Projekt wurde in einem GithubRepository entwickelt und wurde im nachgang in dieses Notebook Ã¼bertragen.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce9b3c",
   "metadata": {},
   "source": [
    "## ðŸ”§ Libraries & Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "e6fd62392feb88db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:03.971132Z",
     "start_time": "2025-06-13T15:46:03.966205Z"
    }
   },
   "source": [
    "from abc import abstractmethod\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from typing import Optional, Sequence, Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from loguru import logger\n",
    "from pydantic import BaseModel\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Recommender deklarieren\n",
    "(Base-Recommender, Collaborative Filtering, Content-Based & Optional noch den Deep-Learning-Recommender)"
   ],
   "id": "1adeaf18e76f57ae"
  },
  {
   "cell_type": "code",
   "id": "813ebe70194fc0a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:03.991154Z",
     "start_time": "2025-06-13T15:46:03.985381Z"
    }
   },
   "source": [
    "class Recommender:\n",
    "    def __init__(self):\n",
    "        self.k = 3 # default\n",
    "        self.user_id = None\n",
    "        self.item_id = None\n",
    "        self.similarity: Literal[\"cosine\", \"pearson\"] = \"cosine\"  # default\n",
    "        self.calculation_variant: Literal[\"weighted\", \"unweighted\"] = \"weighted\"  # default\n",
    "        self.data = None\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def _preprocess_data(self):\n",
    "        ...\n",
    "\n",
    "\n",
    "    def _prepare_information(self, user_id: str, item_id: str, k: int, similarity: Literal[\"cosine\", \"pearson\"] = \"cosine\", calculation_variant: Literal[\"weighted\", \"unweighted\"] = \"weighted\") -> None:\n",
    "        self.user_id = user_id\n",
    "        self.item_id = item_id\n",
    "        self.similarity = similarity\n",
    "        self.calculation_variant = calculation_variant\n",
    "        self.k = k\n",
    "\n",
    "        if similarity == 'pearson' and self.data is not None:\n",
    "            self.data['mean'] = self.data.mean(axis=1)\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(\n",
    "            self,\n",
    "            user_id: str,\n",
    "            item_id: str,\n",
    "            similarity: Optional[Literal['cosine', 'pearson']] = 'cosine',   # only for collaborative filtering\n",
    "            calculation_variety: Optional[Literal['weighted', 'unweighted']] = 'weighted',  # only for collaborative filtering\n",
    "            k: Optional[int] = 3,\n",
    "            second_k_value: Optional[int] = None):\n",
    "        ..."
   ],
   "outputs": [],
   "execution_count": 62
  },
  {
   "cell_type": "code",
   "id": "cad50448f6df9a05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:04.023169Z",
     "start_time": "2025-06-13T15:46:04.006764Z"
    }
   },
   "source": [
    "class CollaborativeFilteringRecommender(Recommender):\n",
    "    def __init__(self, data: pd.DataFrame, mode: Literal['user', 'item'] = 'user', display_results_for_each_step: Optional[bool] = False) -> None:\n",
    "        super().__init__()\n",
    "        self.display_results_for_each_step = display_results_for_each_step\n",
    "        self.original_data = data\n",
    "        self.mode = mode\n",
    "        self._preprocess_data()\n",
    "\n",
    "\n",
    "    def _preprocess_data(self) -> None:\n",
    "        self.original_data = self.original_data.set_index(\"user_ID\")\n",
    "        self.original_data.index = self.original_data.index.astype(str) # convert the index to string (due to error with int values)\n",
    "        if self.mode == 'item':\n",
    "            self.data = self.original_data.T  # transpose for item based\n",
    "        else:\n",
    "            self.data = self.original_data  # original for user based\n",
    "\n",
    "\n",
    "    def _calculate_distance_and_indices(self, dataframe: pd.DataFrame) -> ([], []):\n",
    "        knn = NearestNeighbors(metric=\"cosine\", algorithm='brute')\n",
    "        knn.fit(dataframe.values)\n",
    "        distances, indices = knn.kneighbors(dataframe.values, n_neighbors=self.k + 1)\n",
    "\n",
    "        if self.mode == 'item':\n",
    "            index = dataframe.index.get_loc(self.item_id)\n",
    "        else:\n",
    "            index = dataframe.index.get_loc(self.user_id)\n",
    "\n",
    "        similar_distances = distances[index, 1:]\n",
    "        similar_indices = indices[index, 1:]\n",
    "\n",
    "        return similar_distances, similar_indices\n",
    "\n",
    "    def _calculate_similarities(self, similar_distances: np.ndarray) -> np.ndarray:\n",
    "        similarity = [1 - x for x in similar_distances]\n",
    "        similarity = [(y + 1) / 2 for y in similarity]\n",
    "        return np.array(similarity)\n",
    "\n",
    "    def _calculate_result(self, similarity: np.ndarray, ratings: np.ndarray) -> float:\n",
    "        if self.calculation_variant == \"weighted\":\n",
    "            mean = np.dot(ratings, similarity) / similarity.sum()\n",
    "            return mean\n",
    "        else:\n",
    "            return float(np.mean(ratings))\n",
    "\n",
    "    def _check_values(self) -> None:\n",
    "        if self.mode == 'user':\n",
    "            if self.user_id not in self.data.index:\n",
    "                raise ValueError(f\"User {self.user_id} nicht in Daten.\")\n",
    "            if self.item_id not in self.data.columns:\n",
    "                raise ValueError(f\"Item {self.item_id} nicht in Daten.\")\n",
    "        elif self.mode == 'item':\n",
    "            if self.user_id not in self.original_data.index:\n",
    "                raise ValueError(\n",
    "                    f\"User {self.user_id} nicht in Originaldaten.\")\n",
    "            if self.item_id not in self.data.index:\n",
    "                raise ValueError(\n",
    "                    f\"Item {self.item_id} nicht in transponierten Daten.\")\n",
    "\n",
    "    def _process_item_based(self) -> pd.DataFrame:\n",
    "        user_ratings = self.original_data.loc[self.user_id]\n",
    "\n",
    "        # filter based on the item. Only the users that already gave a rating are relevant\n",
    "        rated_items = user_ratings[user_ratings > 0.0].index.tolist()\n",
    "\n",
    "        if not rated_items:\n",
    "            raise ValueError(f\"User {self.user_id} hat keine Items bewertet!\")\n",
    "\n",
    "        return self.data.loc[rated_items + [self.item_id]]\n",
    "\n",
    "    def _process_user_based(self) -> pd.DataFrame:\n",
    "        # filter based on the item. Only the users that already gave a rating are relevant\n",
    "        relevant_df = self.data[self.data[self.item_id] > 0.0]\n",
    "\n",
    "        # add the user we are looking for (due to non-existing rating this user where filtered out)\n",
    "        return pd.concat([relevant_df, self.data.loc[[self.user_id]]])\n",
    "\n",
    "    def _normalize_for_pearson(self, relevant_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        mean_values = relevant_df.mean(axis=1).to_numpy()\n",
    "        relevant_df = relevant_df.sub(mean_values, axis=0)\n",
    "        return relevant_df\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            user_id: str,\n",
    "            item_id: str,\n",
    "            similarity: Literal['cosine', 'pearson'] = 'cosine',\n",
    "            calculation_variety: Literal['weighted', 'unweighted'] = 'weighted',\n",
    "            k: Optional[int] = 3,\n",
    "            second_k_value: Optional[int] = None) -> float:\n",
    "        self._prepare_information(user_id=user_id, item_id=item_id, similarity=similarity, calculation_variant=calculation_variety, k=k)\n",
    "        self._check_values()\n",
    "\n",
    "        if self.mode == 'item':\n",
    "            relevant_df = self._process_item_based()\n",
    "        else:\n",
    "            relevant_df = self._process_user_based()\n",
    "\n",
    "        if similarity == 'pearson':\n",
    "            self._normalize_for_pearson(relevant_df)\n",
    "\n",
    "        # make sure that there are no NaN values -> set NaN to 0.0\n",
    "        relevant_df = relevant_df.fillna(0.0)\n",
    "        similar_distances, similar_indices = self._calculate_distance_and_indices(dataframe=relevant_df)\n",
    "\n",
    "        if self.mode == 'item':\n",
    "            ratings = relevant_df.iloc[similar_indices][self.user_id].to_numpy()\n",
    "        else:\n",
    "            ratings = relevant_df.iloc[similar_indices][self.item_id].to_numpy()\n",
    "\n",
    "        similarity = self._calculate_similarities(similar_distances)\n",
    "        result = self._calculate_result(similarity, ratings)\n",
    "\n",
    "        if self.display_results_for_each_step:\n",
    "          self.explain(similar_indices, relevant_df, ratings, similarity, result)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def explain(self, similar_indices, relevant_df, ratings, similarity, result) -> None:\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"<mode: {self.mode}>\")\n",
    "        print(f\"({self.calculation_variant}) Mittelwert: {result:.4f}\")\n",
    "        print(f\"Metrik: {self.similarity}\")\n",
    "        print()\n",
    "        print(f\"k ({self.k}) Ã¤hnlichsten {'Items' if self.mode == 'item' else 'Nutzer'}:\")\n",
    "        df = pd.DataFrame({\n",
    "            \"ID\": relevant_df.index[similar_indices],\n",
    "            \"rating\": ratings,\n",
    "            \"similarity\": similarity\n",
    "        }).reset_index(drop=True)\n",
    "        print(df.to_string(index=True, header=True))\n",
    "        print(\"-\" * 50)"
   ],
   "outputs": [],
   "execution_count": 63
  },
  {
   "cell_type": "code",
   "id": "6928825fe8030222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:04.057007Z",
     "start_time": "2025-06-13T15:46:04.038293Z"
    }
   },
   "source": [
    "class ContentBasedRecommender(Recommender):\n",
    "    def __init__(self, item_profile: pd.DataFrame, user_ratings: pd.DataFrame) -> None:\n",
    "        super().__init__()\n",
    "        self.item_profile = item_profile\n",
    "        self.user_ratings = user_ratings\n",
    "        self.k = 3\n",
    "        self.feature_matrix = None\n",
    "        self._preprocess_data()\n",
    "\n",
    "        # check if the features \"budget\", \"revenue\", \"runtime\" are relevant for the item/rating correlation\n",
    "        self._check_features_correlation(features=[\"budget\", \"revenue\", \"runtime\"])\n",
    "        self._calculate_tfidf_matrix()\n",
    "\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        self.item_profile[\"item_ID\"] = self.item_profile[\"item_ID\"].astype(str)\n",
    "        self.user_ratings[\"item_ID\"] = self.user_ratings[\"item_ID\"].astype(str)\n",
    "        self.user_ratings[\"user_ID\"] = self.user_ratings[\"user_ID\"].astype(str)\n",
    "\n",
    "    def _check_features_correlation(self, features: List[str]) -> None:\n",
    "        irrelevant_features = []  #  list for irrelevant feature that will be removed\n",
    "\n",
    "        for feature in features:\n",
    "            if feature not in self.item_profile.columns:\n",
    "                continue\n",
    "\n",
    "            # combine item and user ratings\n",
    "            merged_data = pd.merge(self.user_ratings, self.item_profile, on=\"item_ID\")\n",
    "\n",
    "            # convert to numeric\n",
    "            feature_data = pd.to_numeric(merged_data[feature].fillna(0), errors=\"coerce\")\n",
    "            rating_data = pd.to_numeric(merged_data[\"rating\"].fillna(0), errors=\"coerce\")\n",
    "\n",
    "            # calculate the correlation between the user rating and the feature\n",
    "            correlation, p_value = stats.pearsonr(feature_data, rating_data)\n",
    "\n",
    "            # check if the correlation is relevant / significant\n",
    "            if abs(correlation) < 0.1 or p_value > 0.05:\n",
    "                logger.debug(f\"Feature '{feature}' does not have a sigificant correlation and will be ignored.\")\n",
    "                irrelevant_features.append(feature)\n",
    "            else:\n",
    "                logger.debug(f\"Feature '{feature}' has a significant correlation: {correlation}\")\n",
    "\n",
    "        self.item_profile.drop(columns=irrelevant_features, inplace=True)\n",
    "\n",
    "\n",
    "    def _safe_get_feature(self, feature_name):\n",
    "        if feature_name in self.item_profile.columns:\n",
    "            return self.item_profile[feature_name]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _calculate_tfidf_matrix(self) -> None:\n",
    "        # optional but if the title is empty we set it as an empty string\n",
    "        self.item_profile[\"title\"] = self.item_profile[\"title\"].fillna(\"\")\n",
    "\n",
    "        # use the TfidfVectorizer() to transform title into numerical feature\n",
    "        title_vectorizer = TfidfVectorizer()\n",
    "        title_features = title_vectorizer.fit_transform(self.item_profile[\"title\"])\n",
    "\n",
    "        # change genre columns in text by just extracting the word after '\"Genre_\"'\n",
    "        genre_cols = [col for col in self.item_profile.columns if col.startswith(\"Genre_\")]\n",
    "        if genre_cols:\n",
    "            self.item_profile[\"genre_text\"] = self.item_profile[genre_cols].astype(int).apply(\n",
    "                lambda row: \" \".join([col.replace(\"Genre_\", \"\") for col, val in row.items() if val == 1]), axis=1\n",
    "            )\n",
    "            genre_vectorizer = TfidfVectorizer()\n",
    "            genre_features = genre_vectorizer.fit_transform(self.item_profile[\"genre_text\"])\n",
    "        else:\n",
    "            genre_features = np.empty((len(self.item_profile), 0))\n",
    "\n",
    "        # the language of the items transformed into one-hot-encoded-dummies\n",
    "        language_dummies = pd.get_dummies(self.item_profile[\"original_language\"], prefix=\"lang\")\n",
    "\n",
    "        # put runtime into three categories (short, medium, long)\n",
    "        runtime_feature = self._safe_get_feature(\"runtime\")\n",
    "        if runtime_feature is not None:\n",
    "            runtime_bucket = pd.qcut(runtime_feature, q=3, labels=[\"kurz\", \"mittel\", \"lang\"])\n",
    "            runtime_dummies = pd.get_dummies(runtime_bucket, prefix=\"runtime\")\n",
    "        else:\n",
    "            runtime_dummies = pd.DataFrame(index=self.item_profile.index)\n",
    "\n",
    "        # budget and include will be logarithmically transformed and then scaled\n",
    "        numerical_features = []\n",
    "        if \"budget\" in self.item_profile.columns:\n",
    "            self.item_profile[\"log_budget\"] = np.log1p(self.item_profile[\"budget\"].fillna(0))\n",
    "            numerical_features.append(\"log_budget\")\n",
    "        if \"revenue\" in self.item_profile.columns:\n",
    "            self.item_profile[\"log_revenue\"] = np.log1p(self.item_profile[\"revenue\"].fillna(0))\n",
    "            numerical_features.append(\"log_revenue\")\n",
    "\n",
    "        if numerical_features:\n",
    "            scaler = StandardScaler()\n",
    "            scaled_numericals = scaler.fit_transform(self.item_profile[numerical_features])\n",
    "        else:\n",
    "            scaled_numericals = np.empty((len(self.item_profile), 0))\n",
    "\n",
    "        # create feature matrix\n",
    "        self.feature_matrix = hstack([\n",
    "            title_features,\n",
    "            genre_features,\n",
    "            language_dummies.values,\n",
    "            runtime_dummies.values,\n",
    "            scaled_numericals\n",
    "        ])\n",
    "\n",
    "        self.feature_matrix = csr_matrix(self.feature_matrix)\n",
    "\n",
    "    def _check_values(self):\n",
    "        if self.user_id not in self.user_ratings[\"user_ID\"].values:\n",
    "            raise ValueError(f\"User-ID {self.user_id} not found.\")\n",
    "\n",
    "        if self.item_id not in self.item_profile[\"item_ID\"].values:\n",
    "            raise ValueError(f\"Item-ID {self.item_id} not found.\")\n",
    "\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            user_id: str,\n",
    "            item_id: str,\n",
    "            similarity: Optional[Literal['cosine', 'pearson']] = 'cosine',  # only for collaborative filtering\n",
    "            calculation_variety: Optional[Literal['weighted', 'unweighted']] = 'weighted', # only for collaborative filtering\n",
    "            k: Optional[int] = 3,\n",
    "            second_k_value: Optional[int] = None) -> float:\n",
    "\n",
    "        # default function to save all the information\n",
    "        self._prepare_information(user_id=user_id, item_id=item_id, k=k)\n",
    "\n",
    "        # check if the values included in the dataframes\n",
    "        self._check_values()\n",
    "\n",
    "        # extract only the items, the user rated\n",
    "        rated_items = self.user_ratings[self.user_ratings[\"user_ID\"] == user_id]\n",
    "        rated_item_ids = rated_items[\"item_ID\"].values\n",
    "\n",
    "        # this case can happen when k is greater than the rated items by the user\n",
    "        if self.k > len(rated_item_ids):\n",
    "            self.k = len(rated_item_ids)\n",
    "\n",
    "        # extract the rated item indices from the item profile\n",
    "        rated_item_indices = self.item_profile[self.item_profile[\"item_ID\"].isin(rated_item_ids)].index\n",
    "\n",
    "        # check if the user rated some items... if not then return 0.0\n",
    "        if len(rated_item_indices) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        # get the feature matrix that is calculated in the '_calculate_tfidf_matrix()'-Method\n",
    "        filtered_matrix = self.feature_matrix[rated_item_indices]\n",
    "\n",
    "        # default kNN usage like in the lecture with brute algorithm and cosine as metric\n",
    "        knn = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "        knn.fit(filtered_matrix)\n",
    "\n",
    "        item_index = self.item_profile[self.item_profile[\"item_ID\"] == item_id].index[0]\n",
    "        distances, indices = knn.kneighbors(self.feature_matrix[item_index], n_neighbors=self.k + 1)  # k+1 because the item itself is also included\n",
    "\n",
    "        # the similar item indices beginning with the first real neighbor\n",
    "        similar_items = indices.flatten()[1:]\n",
    "        similar_item_indices = rated_item_indices[similar_items]\n",
    "\n",
    "        # extract for each item in the similar item indices list the rating and save it in the list\n",
    "        similar_ratings = []\n",
    "        for idx in similar_item_indices:\n",
    "            similar_item_id = self.item_profile.iloc[idx][\"item_ID\"]\n",
    "            user_rating = self.user_ratings[(self.user_ratings[\"user_ID\"] == user_id) & (self.user_ratings[\"item_ID\"] == similar_item_id)]\n",
    "            if not user_rating.empty:\n",
    "                similar_ratings.append(user_rating[\"rating\"].values[0])\n",
    "\n",
    "        # if the similar ratings is zero then we return a default 0.0\n",
    "        if not similar_ratings:\n",
    "            return 0.0\n",
    "\n",
    "        # calculate the predicted rating based on the sum of ratings and len of ratings\n",
    "        return sum(similar_ratings) / len(similar_ratings)"
   ],
   "outputs": [],
   "execution_count": 64
  },
  {
   "cell_type": "code",
   "id": "c8fbff7bb11954ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:04.076154Z",
     "start_time": "2025-06-13T15:46:04.070230Z"
    }
   },
   "source": [
    "class HybridRecommender(Recommender):\n",
    "    def __init__(self, data: pd.DataFrame, item_profile: pd.DataFrame, user_ratings: pd.DataFrame, mode: Literal['user', 'item'] = 'user', alpha: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.collaborative_recommender = CollaborativeFilteringRecommender(data=data, mode=mode)\n",
    "        self.content_based_recommender = ContentBasedRecommender(item_profile=item_profile, user_ratings=user_ratings)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            user_id: str,\n",
    "            item_id: str,\n",
    "            similarity: Optional[Literal['cosine', 'pearson']] = 'cosine',  # only for collaborative filtering\n",
    "            calculation_variety: Optional[Literal['weighted', 'unweighted']] = 'weighted', # only for collaborative filtering\n",
    "            k: Optional[int] = 3,\n",
    "            second_k_value: Optional[int] = 3):\n",
    "\n",
    "        collaborative_prediction = self.collaborative_recommender.predict(\n",
    "            user_id=user_id,\n",
    "            item_id=item_id,\n",
    "            similarity=similarity, # ignore that it can be NONE\n",
    "            calculation_variety=calculation_variety, # ignore that it can be NONE\n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        content_based_prediction = self.content_based_recommender.predict(\n",
    "            user_id=user_id,\n",
    "            item_id=item_id,\n",
    "            similarity=similarity,\n",
    "            calculation_variety=calculation_variety,\n",
    "            k=second_k_value\n",
    "        )\n",
    "\n",
    "        # combine both with alpha as weight\n",
    "        combined_prediction = (self.alpha * collaborative_prediction) + ((1 - self.alpha) * content_based_prediction)\n",
    "        return combined_prediction"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "d160643fb14f6b77"
  },
  {
   "cell_type": "markdown",
   "id": "be84f149",
   "metadata": {},
   "source": "`OPTIONAL`  Deep-Learning-Recomender"
  },
  {
   "cell_type": "code",
   "id": "dfc14af51f24d030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:04.118910Z",
     "start_time": "2025-06-13T15:46:04.092642Z"
    }
   },
   "source": [
    "class RatingsDataset(Dataset):\n",
    "     # PyTorch dataset that returns (user_idx, item_idx, rating) tuples\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        # cast once to tensors that avoids conversions inside the training loop\n",
    "        self.u = torch.tensor(df[\"user_idx\"].values, dtype=torch.long)\n",
    "        self.i = torch.tensor(df[\"item_idx\"].values, dtype=torch.long)\n",
    "        self.r = torch.tensor(df[\"rating\"].values, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return len(self.r)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.u[idx], self.i[idx], self.r[idx]\n",
    "\n",
    "\n",
    "class HybridMF(nn.Module):\n",
    "    # Matrixâ€‘factorisation with bias terms + linear projection of item features\n",
    "    def __init__(self, num_users: int, num_items: int, d: int, item_features: torch.Tensor, dropout: float = 0.15):\n",
    "        super().__init__()\n",
    "\n",
    "        # user / item embeddings (latent factors)\n",
    "        self.P = nn.Embedding(num_users, d)\n",
    "        self.Q = nn.Embedding(num_items, d)\n",
    "\n",
    "        # bias embeddings\n",
    "        self.bu = nn.Embedding(num_users, 1)\n",
    "        self.bi = nn.Embedding(num_items, 1)\n",
    "        self.mu = nn.Parameter(torch.zeros(1))  # global mean\n",
    "\n",
    "        # linear projection that maps item sideâ€‘features into the same latent space\n",
    "        self.F = nn.Linear(item_features.shape[1], d, bias=False)\n",
    "        self.register_buffer(\"item_features\", item_features)  # moved to GPU/CPU automatically to improve performance based on system\n",
    "\n",
    "        # dropout for a bit of regularisation\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        # lightweight weight initialisation\n",
    "        nn.init.normal_(self.P.weight, std=0.05)\n",
    "        nn.init.normal_(self.Q.weight, std=0.05)\n",
    "        nn.init.xavier_uniform_(self.F.weight)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "         # build item representation: latent factors + projected features\n",
    "        q = self.Q(i) + self.F(self.item_features[i])\n",
    "        q = self.drop(q)\n",
    "\n",
    "        # final prediction for each (u,i) pair\n",
    "        return (self.P(u) * q).sum(-1) + self.mu + self.bu(u).squeeze() + self.bi(i).squeeze()  # product of latent vectors + global bias + user bias + item bias\n",
    "\n",
    "\n",
    "class DeepLearningRecommender(Recommender):\n",
    "        # Preâ€‘processing, training loop, evaluation & prediction are encapsulated here.\n",
    "        def __init__(\n",
    "            self,\n",
    "            ratings: pd.DataFrame,\n",
    "            item_profile: pd.DataFrame,\n",
    "            numeric_cols: Optional[Sequence[str]] = (\"runtime\", \"budget\", \"revenue\"),\n",
    "            val_ratio: float = 0.2,\n",
    "            embedding_dim: int = 64,\n",
    "            batch_size: int = 1024,\n",
    "            epochs: int = 60,\n",
    "            lr: float = 1e-3,\n",
    "            weight_decay: float = 3e-5,\n",
    "            dropout_p: float = 0.20,\n",
    "            early_stopping_rounds: int = 10,\n",
    "            device: Optional[str] = None,\n",
    "            seed: int = 42,\n",
    "        ):\n",
    "            super().__init__()\n",
    "\n",
    "            self.embedding_dim = embedding_dim\n",
    "            self.batch_size = batch_size\n",
    "            self.epochs = epochs\n",
    "            self.lr = lr\n",
    "            self.weight_decay = weight_decay\n",
    "            self.dropout_p = dropout_p\n",
    "            self.early_stopping_rounds = early_stopping_rounds\n",
    "            self.seed = seed\n",
    "            self.device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "            self.ratings_raw = ratings.copy()\n",
    "            self.item_profile_raw = item_profile.copy()\n",
    "            self.numeric_cols = numeric_cols\n",
    "            self.val_ratio = val_ratio\n",
    "\n",
    "            # complete preparation + training pipeline\n",
    "            self._preprocess_data()\n",
    "            self._build_model()\n",
    "            self.fit()  # autoâ€‘train so that external testers donâ€™t need to call fit()\n",
    "\n",
    "\n",
    "        def _preprocess_data(self):\n",
    "            # cast ids to str to avoid categorical type issues\n",
    "            self.ratings_raw[[\"user_ID\", \"item_ID\"]] = self.ratings_raw[[\"user_ID\", \"item_ID\"]].astype(str)\n",
    "\n",
    "            # dense id mapping\n",
    "            self.user2idx = {u: i for i, u in enumerate(self.ratings_raw[\"user_ID\"].unique())}\n",
    "            self.item2idx = {m: j for j, m in enumerate(self.ratings_raw[\"item_ID\"].unique())}\n",
    "            self.idx2user = {i: u for u, i in self.user2idx.items()}\n",
    "            self.idx2item = {j: m for m, j in self.item2idx.items()}\n",
    "\n",
    "            ratings = self.ratings_raw.copy()\n",
    "            ratings[\"user_idx\"] = ratings[\"user_ID\"].map(self.user2idx)\n",
    "            ratings[\"item_idx\"] = ratings[\"item_ID\"].map(self.item2idx)\n",
    "\n",
    "            # Feature matrix (oneâ€‘hot genres + scaled numeric cols)\n",
    "            ip = self.item_profile_raw[self.item_profile_raw[\"item_ID\"].isin(self.item2idx)].copy()\n",
    "            ip[\"item_idx\"] = ip[\"item_ID\"].map(self.item2idx)\n",
    "            ip.sort_values(\"item_idx\", inplace=True)\n",
    "            feat_df = ip.filter(regex=\"^Genre_\")   # already oneâ€‘hot 0/1 columns\n",
    "\n",
    "            # numeric columns (if present)\n",
    "            if self.numeric_cols:\n",
    "                present = [c for c in self.numeric_cols if c in ip.columns]\n",
    "                if missing := set(self.numeric_cols) - set(present):\n",
    "                    logger.warning(f\"Skipped numeric cols: {missing}\")\n",
    "                if present and not ip.empty:\n",
    "                    feat_df[present] = StandardScaler().fit_transform(ip[present].fillna(0))\n",
    "                elif present:\n",
    "                    # no rows â€“> create zero columns to keep matrix shape consistent\n",
    "                    for col in present:\n",
    "                        feat_df[col] = 0\n",
    "\n",
    "            # if no features at all â€“ fallback to a single zero column\n",
    "            self.feat_mat = torch.tensor(feat_df.values if not feat_df.empty else np.zeros((len(self.item2idx), 1)), dtype=torch.float32)\n",
    "\n",
    "            # optional but \"why-not\"...  global mean used for coldâ€‘start cases\n",
    "            self.global_mean = ratings[\"rating\"].mean()\n",
    "\n",
    "            # pivot for optional Pearson similarity (required by base class... for testing we do not remove this)\n",
    "            self.data = ratings.pivot(index=\"user_ID\", columns=\"item_ID\", values=\"rating\")\n",
    "\n",
    "            # create loaders\n",
    "            train_df, val_df = train_test_split(ratings, test_size=self.val_ratio, random_state=self.seed)\n",
    "            self.train_loader = DataLoader(RatingsDataset(train_df), batch_size=self.batch_size, shuffle=True)\n",
    "            self.val_loader = DataLoader(RatingsDataset(val_df), batch_size=self.batch_size)\n",
    "\n",
    "        # model construction\n",
    "        def _build_model(self):\n",
    "            self.model = HybridMF(\n",
    "                num_users=len(self.user2idx),\n",
    "                num_items=len(self.item2idx),\n",
    "                d=self.embedding_dim,\n",
    "                item_features=self.feat_mat,\n",
    "                dropout=self.dropout_p,\n",
    "            ).to(self.device)\n",
    "\n",
    "\n",
    "        def fit(self):\n",
    "            # Adam optimiser... suited for sparse embeddings\n",
    "            opt = optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "\n",
    "            # scheduler lowers LR (Learn-Rate) by Ã—0.5 if valâ€‘MAE plateaus for 3 epochs\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3)\n",
    "\n",
    "            best_mae, epochs_no_imp = float(\"inf\"), 0  # track earlyâ€‘stopping progress\n",
    "\n",
    "            for ep in range(1, self.epochs + 1):\n",
    "                self.model.train()\n",
    "                # iterate over miniâ€‘batches (u,i,r) from DataLoader\n",
    "                for u, i, r in self.train_loader:\n",
    "                    # move to device once per batch\n",
    "                    u, i, r = u.to(self.device), i.to(self.device), r.to(self.device)\n",
    "\n",
    "                    opt.zero_grad()  # reset gradients\n",
    "                    pred = self.model(u, i) # forward pass\n",
    "\n",
    "                    # Smooth L1 â‰ˆ MAE for |err|>Î², MSE for |err|<Î² â€“ stable & robust\n",
    "                    loss = nn.functional.smooth_l1_loss(pred, r, beta=1.0)\n",
    "                    loss.backward() # backâ€‘prop\n",
    "                    opt.step() # Adam update\n",
    "\n",
    "                # validation after each epoch\n",
    "                val_mae = self._evaluate_loader(self.val_loader)\n",
    "                logger.info(f\"ep{ep:02d} â€¢ val MAE {val_mae:.4f}\")\n",
    "                scheduler.step(val_mae)  # maybe reduce LR\n",
    "\n",
    "                # earlyâ€‘stopping logic\n",
    "                if val_mae + 1e-4 < best_mae:           # question: significant improvement? ... yes / no?\n",
    "                    best_mae, epochs_no_imp = val_mae, 0\n",
    "                    torch.save(self.model.state_dict(), \"hybrid_best.pt\")  # checkpoint (save in file)\n",
    "                else:\n",
    "                    epochs_no_imp += 1\n",
    "                    if epochs_no_imp >= self.early_stopping_rounds:\n",
    "                        break  # stop training...\n",
    "\n",
    "            # restore best weights before evaluation\n",
    "            self.model.load_state_dict(torch.load(\"hybrid_best.pt\"))\n",
    "\n",
    "        # helper to evaluate loaders\n",
    "        def _evaluate_loader(self, loader):\n",
    "            # computes Mean Absolute Error over a given DataLoader\n",
    "            self.model.eval(); err, n = 0.0, 0\n",
    "            with torch.no_grad():\n",
    "                for u, i, r in loader:\n",
    "                    preds = self.model(u.to(self.device), i.to(self.device)).cpu()\n",
    "                    err += torch.abs(preds - r).sum().item(); n += len(r)\n",
    "            return err / n\n",
    "\n",
    "\n",
    "        # default prediction method from base class\n",
    "        def predict(\n",
    "            self,\n",
    "            user_id: str,\n",
    "            item_id: str,\n",
    "            similarity: Optional[Literal['cosine', 'pearson']] = 'cosine',\n",
    "            calculation_variety: Optional[Literal['weighted', 'unweighted']] = 'weighted',\n",
    "            k: Optional[int] = 3,\n",
    "            second_k_value: Optional[int] = None,\n",
    "        ) -> float:\n",
    "            self._prepare_information(user_id, item_id, k, similarity, calculation_variety)  # ignore that this can be none... just a \"simple\" test recommender here\n",
    "\n",
    "            # check if the user or item is not known\n",
    "            if user_id not in self.user2idx and item_id not in self.item2idx:\n",
    "                return float(self.global_mean)\n",
    "\n",
    "            # case 1: only user is unknown so we take the item-bias\n",
    "            if user_id not in self.user2idx:\n",
    "                idx = self.item2idx.get(item_id)\n",
    "                if idx is None:\n",
    "                    return float(self.global_mean)\n",
    "                item_bias = self.model.bi.weight[idx].item()\n",
    "                return float(np.clip(self.global_mean + item_bias, 0.5, 5.0))\n",
    "\n",
    "            # case 2: only item is unknown so we take the user-bias\n",
    "            if item_id not in self.item2idx:\n",
    "                u_idx = self.user2idx[user_id]\n",
    "                user_bias = self.model.bu.weight[u_idx].item()\n",
    "                return float(np.clip(self.global_mean + user_bias, 0.5, 5.0))\n",
    "\n",
    "            # case 3 - both unnown (default case)\n",
    "            u = torch.tensor([self.user2idx[user_id]], device=self.device)\n",
    "            i = torch.tensor([self.item2idx[item_id]], device=self.device)\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                score = self.model(u, i).item()\n",
    "            return float(np.clip(score, 0.5, 5.0))"
   ],
   "outputs": [],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "333ff78ed02f42f6"
  },
  {
   "cell_type": "markdown",
   "id": "f36958e4",
   "metadata": {},
   "source": [
    "## MAE Tester\n",
    "Verwendet, um die verschiedenen Recommender zu Evaluieren und anhand des MAEs zu vergleichen"
   ]
  },
  {
   "cell_type": "code",
   "id": "bd623ba6223a9825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:04.157911Z",
     "start_time": "2025-06-13T15:46:04.132301Z"
    }
   },
   "source": [
    "class Test(BaseModel):\n",
    "    name: str\n",
    "    type: Literal[\"collaborative_filtering\", \"content_based\", \"hybrid\", \"deep_learning\"]\n",
    "    mode: Optional[Literal[\"user\", \"item\"]] = \"item\"\n",
    "    k_value: Optional[int] = 3\n",
    "    second_k_value: Optional[int] = 3\n",
    "    metric: Optional[Literal[\"cosine\", \"pearson\"]] = 'cosine'\n",
    "    calculation_variety: Optional[Literal[\"weighted\", \"unweighted\"]] = 'weighted'\n",
    "    batch_size: Optional[int] = 128\n",
    "    embedding_dim: Optional[int] = 16\n",
    "    epochs: Optional[int] = 25\n",
    "    alpha: Optional[float] = 0.5\n",
    "\n",
    "\n",
    "class TestResult(BaseModel):\n",
    "    name: str\n",
    "    type: Literal[\"collaborative_filtering\", \"content_based\", \"hybrid\", \"deep_learning\"]\n",
    "    mode: Literal[\"user\", \"item\"] | None\n",
    "    k_value: int | None\n",
    "    second_k_value: int | None\n",
    "    metric: Literal[\"cosine\", \"pearson\"] | None\n",
    "    calculation_variety: Literal[\"weighted\", \"unweighted\"] | None\n",
    "    alpha: float | None\n",
    "    epochs: int | None\n",
    "    batch_size: int | None\n",
    "    embedding_dim: int | None\n",
    "    mae: float\n",
    "\n",
    "\n",
    "class TestResults(BaseModel): # just for saving in a \"pretty\" form\n",
    "    date: str\n",
    "    num_tests: int\n",
    "    best_test: TestResult\n",
    "    results: List[TestResult]\n",
    "\n",
    "\n",
    "\n",
    "class MAETester:\n",
    "    def __init__(self, tests: List[Test], test_data_path: str, data_path: str, item_profile_path: str, ratings: str):\n",
    "        self.tests = tests\n",
    "        self.testdata = pd.read_csv(test_data_path)  # testdata (for evaluaton)\n",
    "        self.item_profile = pd.read_csv(item_profile_path)\n",
    "        self.user_ratings = pd.read_csv(ratings)\n",
    "        self._prepare_data()\n",
    "        self.data = pd.read_csv(data_path)  # trainings-data\n",
    "        self.results: List[TestResult] = []\n",
    "\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        self.testdata[\"user_ID\"] = self.testdata[\"user_ID\"].astype(str)\n",
    "        self.testdata[\"item_ID\"] = self.testdata[\"item_ID\"].astype(str)\n",
    "\n",
    "    # because we only have 0.5 steps in testdata\n",
    "    @staticmethod\n",
    "    def _round_to_nearest_half(value: float):\n",
    "        return round(value * 2) / 2\n",
    "\n",
    "    def run_tests(self) -> pd.DataFrame:\n",
    "        for test in self.tests:\n",
    "            result = self._run_test(test)\n",
    "            self.results.append(result)\n",
    "            logger.success(f\"Test abgeschlossen: {test.name}, MAE: {result.mae:.4f}\\n\")\n",
    "\n",
    "        # display final resultse\n",
    "        result_df = self._summarize_test_results()\n",
    "\n",
    "        # save final results to file\n",
    "        self._save_to_file()\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def _run_test(self, test: Test) -> TestResult:\n",
    "        logger.info(f\"Running test: {test.name}\")\n",
    "\n",
    "        if test.type == \"content_based\":\n",
    "            recommender = ContentBasedRecommender(\n",
    "                item_profile=self.item_profile,\n",
    "                user_ratings=self.user_ratings,\n",
    "            )\n",
    "        elif test.type == \"collaborative_filtering\":\n",
    "            recommender = CollaborativeFilteringRecommender(\n",
    "                mode=test.mode, # ignore type (that this can be NONE)\n",
    "                data=self.data,\n",
    "            )\n",
    "        elif test.type == \"hybrid\":\n",
    "            recommender = HybridRecommender(\n",
    "                data=self.data,\n",
    "                item_profile=self.item_profile,\n",
    "                user_ratings=self.user_ratings,\n",
    "                mode=test.mode,  # ignore type (that this can be NONE)\n",
    "                alpha=test.alpha,\n",
    "            )\n",
    "        elif test.type == \"deep_learning\":\n",
    "            recommender = DeepLearningRecommender(\n",
    "                ratings=self.user_ratings,\n",
    "                batch_size=test.batch_size,\n",
    "                epochs=test.epochs,\n",
    "                embedding_dim=test.embedding_dim,\n",
    "                item_profile=self.item_profile\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unbekannter Recomendertyp: {test.type}\")\n",
    "\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "\n",
    "        testdata_list = self.testdata.to_numpy()\n",
    "\n",
    "        for row in tqdm(testdata_list, desc=\"Vorhersagen werden berechnet\"):\n",
    "            user_id: str = str(row[0])\n",
    "            item_id: str = str(row[1])\n",
    "            actual_rating = row[2]\n",
    "\n",
    "            try:\n",
    "                predicted_rating = recommender.predict(\n",
    "                    user_id=user_id,\n",
    "                    item_id=item_id,\n",
    "                    similarity=test.metric,\n",
    "                    calculation_variety=test.calculation_variety,\n",
    "                    k=test.k_value,\n",
    "                    second_k_value=test.second_k_value,\n",
    "                )\n",
    "                #\n",
    "                # predicted_rating = self._round_to_nearest_half(value=predicted_rating)\n",
    "\n",
    "                predictions.append(predicted_rating)\n",
    "                actuals.append(actual_rating)\n",
    "            except ValueError as e:\n",
    "                logger.warning(f\"Fehler bei der Vorhersage: {e}\")\n",
    "\n",
    "        mae = self._mean_absolute_error(actuals, predictions)\n",
    "\n",
    "        return TestResult(\n",
    "            name=test.name,\n",
    "            type=test.type,\n",
    "            mode=test.mode,\n",
    "            k_value=test.k_value,\n",
    "            metric=test.metric,\n",
    "            calculation_variety=test.calculation_variety,\n",
    "            alpha=test.alpha,\n",
    "            batch_size=test.batch_size,\n",
    "            embedding_dim=test.embedding_dim,\n",
    "            epochs=test.epochs,\n",
    "            second_k_value=test.second_k_value,\n",
    "            mae=mae,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _mean_absolute_error(actuals: List[float], predictions: List[float]) -> float:\n",
    "        if not actuals or not predictions or len(actuals) != len(predictions):\n",
    "            raise ValueError(\"Listen fÃ¼r tatsÃ¤chliche und vorhergesagte Werte mÃ¼ssen gleich lang und nicht leer sein.\")\n",
    "\n",
    "        absolute_errors = [abs(a - p) for a, p in zip(actuals, predictions)]\n",
    "        mae = sum(absolute_errors) / len(absolute_errors)\n",
    "        return mae\n",
    "\n",
    "    def _summarize_test_results(self) -> pd.DataFrame:\n",
    "        if not self.results:\n",
    "            logger.info(\"Keine Testergebnisse vorhanden.\")\n",
    "            return\n",
    "\n",
    "        summary_df = pd.DataFrame([{\n",
    "            \"Testname\": result.name,\n",
    "            \"Recomendertyp\": result.type,\n",
    "            \"Modus\": result.mode if result.type == \"collaborative_filtering\" else \"/\",\n",
    "            \"k-Wert\": result.k_value if result.type != \"deep_learning\" else \"/\",\n",
    "            \"Metrik\": result.metric if result.type == \"collaborative_filtering\" else \"/\",\n",
    "            \"Berechnungsvariante\": result.calculation_variety if result.type == \"collaborative_filtering\" else \"/\",\n",
    "            \"Alpha (weight)\": result.alpha if result.type == \"hybrid\" else \"/\",\n",
    "            \"Batch-GrÃ¶ÃŸe\": result.batch_size if result.type == \"deep_learning\" else \"/\",\n",
    "            \"Embedding-Dimension\": result.embedding_dim if result.type == \"deep_learning\" else \"/\",\n",
    "            \"Epochen\": result.epochs if result.type == \"deep_learning\" else \"/\",\n",
    "            \"MAE\": result.mae\n",
    "        } for result in self.results])\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Zusammenfassung der Testergebnisse:\")\n",
    "        print(summary_df.to_string(index=False))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        return summary_df\n",
    "\n",
    "\n",
    "    def _save_to_file(self) -> None:\n",
    "        if not self.results:\n",
    "            logger.info(\"Keine Testergebnisse vorhanden, nichts zu speichern.\")\n",
    "            return\n",
    "        date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        best_test = min(self.results, key=lambda result: result.mae)  # best results based on mae\n",
    "        test_results = TestResults(\n",
    "            date=date,\n",
    "            num_tests=len(self.results),\n",
    "            best_test=best_test,\n",
    "            results=self.results\n",
    "        )\n",
    "\n",
    "        file_path = f\"./outputs/testergebnis_{date.replace(':', '-')}.json\"\n",
    "\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json_file.write(test_results.model_dump_json(indent=4))\n",
    "\n",
    "        logger.success(f\"Testergebnisse erfolgreich gespeichert.\")"
   ],
   "outputs": [],
   "execution_count": 67
  },
  {
   "cell_type": "markdown",
   "id": "d924f474e12c71d9",
   "metadata": {},
   "source": [
    "# Beginn der Aufrufe und Nutzung der Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af79d55b715866d",
   "metadata": {},
   "source": [
    "wir haben viele TestfÃ¤lle durchgefÃ¼hrt (diese sind ganz unten zu finden) und uns dann aufgrund der MAE-Ergebnisse fÃ¼r folgenden Hybriden Recommender entschieden der sowohl CollaborativeFiltering als auch Conten-Based-Filtering berÃ¼cksichtigt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593c5f25d4441af",
   "metadata": {},
   "source": [
    "Um diesen Recommender zu testen stellen wir eine struktur bereit wobei lediglich der parameter `testdata` angepasst werden muss um den evaluationsdatensatz zu verwenden. Aufrgund der sehr nah beieinanderliegenden Ergebnisse fÃ¼r pearson und cosine stellen wir beide Testprofile zur VerfÃ¼gung."
   ]
  },
  {
   "cell_type": "code",
   "id": "3b9bbc3845fde0ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:04.181120Z",
     "start_time": "2025-06-13T15:46:04.177183Z"
    }
   },
   "source": [
    "choosen_recommender_profile = [\n",
    "    Test(name=\"HybridRecommender\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.5),\n",
    "    Test(name=\"HybridRecommender\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.5)\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 68
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "758ad31df10683b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Optionale (andere) Testprofile die verwendet wurden und vollstÃ¤ndigkeitshalber hier aufgefÃ¼hrt sind",
   "id": "649e17ae98cdff8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:04.207854Z",
     "start_time": "2025-06-13T15:46:04.200287Z"
    }
   },
   "cell_type": "code",
   "source": [
    "collaborative_filtering_profiles = [\n",
    "    Test(name=\"UserBased_1_cosine\", type=\"collaborative_filtering\", mode=\"user\", k_value=4, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"UserBased_2_cosine\", type=\"collaborative_filtering\", mode=\"user\", k_value=3, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"UserBased_3_cosine\", type=\"collaborative_filtering\", mode=\"user\", k_value=4, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"UserBased_4_cosine\", type=\"collaborative_filtering\", mode=\"user\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "\n",
    "    Test(name=\"ItemBased_1_cosine\", type=\"collaborative_filtering\", mode=\"item\", k_value=4, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"ItemBased_2_cosine\", type=\"collaborative_filtering\", mode=\"item\", k_value=3, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"ItemBased_3_cosine\", type=\"collaborative_filtering\", mode=\"item\", k_value=4, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"ItemBased_4_cosine\", type=\"collaborative_filtering\", mode=\"item\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "\n",
    "    Test(name=\"UserBased_1_pearson\", type=\"collaborative_filtering\", mode=\"user\", k_value=4, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"UserBased_2_pearson\", type=\"collaborative_filtering\", mode=\"user\", k_value=3, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"UserBased_3_pearson\", type=\"collaborative_filtering\", mode=\"user\", k_value=4, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"UserBased_4_pearson\", type=\"collaborative_filtering\", mode=\"user\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "\n",
    "    Test(name=\"ItemBased_1_pearson\", type=\"collaborative_filtering\", mode=\"item\", k_value=4, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"ItemBased_2_pearson\", type=\"collaborative_filtering\", mode=\"item\", k_value=3, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"ItemBased_3_pearson\", type=\"collaborative_filtering\", mode=\"item\", k_value=4, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"ItemBased_4_pearson\", type=\"collaborative_filtering\", mode=\"item\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "]"
   ],
   "id": "588826d545fb7fef",
   "outputs": [],
   "execution_count": 69
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:04.232889Z",
     "start_time": "2025-06-13T15:46:04.227318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content_based_profiles = [\n",
    "    Test(name=\"ContentBased_1\", type=\"content_based\", k_value=3),\n",
    "    Test(name=\"ContentBased_2\", type=\"content_based\", k_value=4),\n",
    "    Test(name=\"ContentBased_3\", type=\"content_based\", k_value=5),\n",
    "    Test(name=\"ContentBased_4\", type=\"content_based\", k_value=6),\n",
    "    Test(name=\"ContentBased_5\", type=\"content_based\", k_value=7),\n",
    "    Test(name=\"ContentBased_6\", type=\"content_based\", k_value=8),\n",
    "    Test(name=\"ContentBased_7\", type=\"content_based\", k_value=9),\n",
    "    Test(name=\"ContentBased_8\", type=\"content_based\", k_value=10),\n",
    "    Test(name=\"ContentBased_9\", type=\"content_based\", k_value=11),\n",
    "    Test(name=\"ContentBased_10\", type=\"content_based\", k_value=12),\n",
    "    Test(name=\"ContentBased_11\", type=\"content_based\", k_value=13),\n",
    "    Test(name=\"ContentBased_12\", type=\"content_based\", k_value=14),\n",
    "]"
   ],
   "id": "d1df2dc28368aa35",
   "outputs": [],
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "id": "45018afb4c4d0655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:04.266110Z",
     "start_time": "2025-06-13T15:46:04.261987Z"
    }
   },
   "source": [
    "deep_learning_profiles = [\n",
    "    # Test(name=\"deep_learning_large_embedding\", type=\"deep_learning\", embedding_dim=128, epochs=25, batch_size=128),\n",
    "    # Test(name=\"deep_learning_small_batch\", type=\"deep_learning\", embedding_dim=64, epochs=25, batch_size=64),\n",
    "    # Test(name=\"deep_learning_large_batch\", type=\"deep_learning\", embedding_dim=64, epochs=25, batch_size=256),\n",
    "    # Test(name=\"deep_learning_more_epochs\", type=\"deep_learning\", embedding_dim=64, epochs=50, batch_size=128),\n",
    "    # Test(name=\"deep_learning_less_epochs\", type=\"deep_learning\", embedding_dim=64, epochs=10, batch_size=128),\n",
    "    # Test(name=\"deep_learning_less_epochs\", type=\"deep_learning\", embedding_dim=64, epochs=10, batch_size=128),\n",
    "    # Test(name=\"deep_learning_finetuning_1\", type=\"deep_learning\", embedding_dim=48, epochs=10, batch_size=128),\n",
    "    # Test(name=\"deep_learning_finetuning_2\", type=\"deep_learning\", embedding_dim=16, epochs=25, batch_size=128),\n",
    "    Test(name=\"deep_learning_finetuning_3\", type=\"deep_learning\", embedding_dim=16, epochs=25, batch_size=64),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 71
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:04.306244Z",
     "start_time": "2025-06-13T15:46:04.298273Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hybrid_profiles = [\n",
    "    Test(name=\"Hybrid_1\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.5),\n",
    "    Test(name=\"Hybrid_2\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.75),\n",
    "    Test(name=\"Hybrid_3\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.25),\n",
    "\n",
    "    Test(name=\"Hybrid_4\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.5),\n",
    "    Test(name=\"Hybrid_5\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.75),\n",
    "    Test(name=\"Hybrid_6\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.25),\n",
    "\n",
    "    Test(name=\"Hybrid_7\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.5),\n",
    "    Test(name=\"Hybrid_8\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.75),\n",
    "    Test(name=\"Hybrid_9\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.25),\n",
    "\n",
    "    Test(name=\"Hybrid_10\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.5),\n",
    "    Test(name=\"Hybrid_11\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.75),\n",
    "    Test(name=\"Hybrid_12\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.25),\n",
    "\n",
    "]"
   ],
   "id": "90d35683f5188ea9",
   "outputs": [],
   "execution_count": 72
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "c3de1e9f7ef06c96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Aufruf des MAE Testers\n",
    "Dem Tester werden die entscheidenden Daten Ã¼bergeben und anschlieÃŸend wird der MAE fÃ¼r die ausgewÃ¤hlten / Ã¼bergebenene Test-Profile ermittelt"
   ],
   "id": "dab2f1ae84c66fb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:04.331060Z",
     "start_time": "2025-06-13T15:46:04.327355Z"
    }
   },
   "cell_type": "code",
   "source": "testdata_path = \"./data/Testdaten_FlixNet.csv\"   # change to use another Test/Eval-Dataset",
   "id": "ff1a9deee9507f5b",
   "outputs": [],
   "execution_count": 73
  },
  {
   "cell_type": "code",
   "id": "1a177fda3e3854fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:04.419756Z",
     "start_time": "2025-06-13T15:46:04.353898Z"
    }
   },
   "source": [
    "tester = MAETester(\n",
    "        tests=deep_learning_profiles,\n",
    "        test_data_path=testdata_path,\n",
    "        data_path=\"./data/Bewertungsmatrix_FlixNet.csv\",\n",
    "        ratings=\"./data/Ratings_FlixNet.csv\",\n",
    "        item_profile_path=\"./data/Itemprofile_FlixNet.csv\",\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "id": "1259e7059201639c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-13T15:46:15.577927Z",
     "start_time": "2025-06-13T15:46:04.434844Z"
    }
   },
   "source": [
    "result = tester.run_tests()\n",
    "result # print result here as dataframe"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-13 17:46:04.436\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m_run_test\u001B[0m:\u001B[36m73\u001B[0m - \u001B[1mRunning test: deep_learning_finetuning_3\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:04.886\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep01 â€¢ val MAE 3.1049\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:05.301\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep02 â€¢ val MAE 2.8267\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:05.723\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep03 â€¢ val MAE 2.5626\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:06.152\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep04 â€¢ val MAE 2.3039\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:06.555\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep05 â€¢ val MAE 2.0347\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:06.961\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep06 â€¢ val MAE 1.7632\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:07.360\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep07 â€¢ val MAE 1.5114\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:07.756\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep08 â€¢ val MAE 1.3022\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:08.153\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep09 â€¢ val MAE 1.1453\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:08.558\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep10 â€¢ val MAE 1.0379\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:08.957\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep11 â€¢ val MAE 0.9662\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:09.358\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep12 â€¢ val MAE 0.9160\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:09.765\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep13 â€¢ val MAE 0.8815\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:10.170\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep14 â€¢ val MAE 0.8578\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:10.571\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep15 â€¢ val MAE 0.8403\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:10.968\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep16 â€¢ val MAE 0.8273\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:11.369\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep17 â€¢ val MAE 0.8173\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:11.779\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep18 â€¢ val MAE 0.8093\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:12.476\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep19 â€¢ val MAE 0.8028\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:12.933\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep20 â€¢ val MAE 0.7988\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:13.508\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep21 â€¢ val MAE 0.7932\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:13.930\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep22 â€¢ val MAE 0.7895\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:14.341\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep23 â€¢ val MAE 0.7853\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:14.799\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep24 â€¢ val MAE 0.7833\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:15.244\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m173\u001B[0m - \u001B[1mep25 â€¢ val MAE 0.7815\u001B[0m\n",
      "Vorhersagen werden berechnet: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1595/1595 [00:00<00:00, 5090.88it/s]\n",
      "\u001B[32m2025-06-13 17:46:15.567\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mrun_tests\u001B[0m:\u001B[36m62\u001B[0m - \u001B[32m\u001B[1mTest abgeschlossen: deep_learning_finetuning_3, MAE: 0.7619\n",
      "\u001B[0m\n",
      "\u001B[32m2025-06-13 17:46:15.571\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m_save_to_file\u001B[0m:\u001B[36m202\u001B[0m - \u001B[32m\u001B[1mTestergebnisse erfolgreich gespeichert.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Zusammenfassung der Testergebnisse:\n",
      "                  Testname Recomendertyp Modus k-Wert Metrik Berechnungsvariante Alpha (weight)  Batch-GrÃ¶ÃŸe  Embedding-Dimension  Epochen      MAE\n",
      "deep_learning_finetuning_3 deep_learning     /      /      /                   /              /           64                   16       25 0.761889\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                     Testname  Recomendertyp Modus k-Wert Metrik  \\\n",
       "0  deep_learning_finetuning_3  deep_learning     /      /      /   \n",
       "\n",
       "  Berechnungsvariante Alpha (weight)  Batch-GrÃ¶ÃŸe  Embedding-Dimension  \\\n",
       "0                   /              /           64                   16   \n",
       "\n",
       "   Epochen       MAE  \n",
       "0       25  0.761889  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testname</th>\n",
       "      <th>Recomendertyp</th>\n",
       "      <th>Modus</th>\n",
       "      <th>k-Wert</th>\n",
       "      <th>Metrik</th>\n",
       "      <th>Berechnungsvariante</th>\n",
       "      <th>Alpha (weight)</th>\n",
       "      <th>Batch-GrÃ¶ÃŸe</th>\n",
       "      <th>Embedding-Dimension</th>\n",
       "      <th>Epochen</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deep_learning_finetuning_3</td>\n",
       "      <td>deep_learning</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>64</td>\n",
       "      <td>16</td>\n",
       "      <td>25</td>\n",
       "      <td>0.761889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 75
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
