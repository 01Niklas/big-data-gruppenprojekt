{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ffb10be",
   "metadata": {},
   "source": [
    "# Gruppenprojekt - Big Data Analysis\n",
    "Dieses Notebook beschreibt unser Programm und bietet einen Ãœberblik Ã¼ber unser Projekt mit den *FlixNet*â€‘Daten.\n",
    "\n",
    "***INFO**: Dieses Projekt wurde in einem GithubRepository entwickelt und wurde im nachgang in dieses Notebook Ã¼bertragen.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bce9b3c",
   "metadata": {},
   "source": [
    "## ðŸ”§ Libraries & Setup"
   ]
  },
  {
   "cell_type": "code",
   "id": "e6fd62392feb88db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:40.968456Z",
     "start_time": "2025-06-16T13:08:40.962780Z"
    }
   },
   "source": [
    "from abc import abstractmethod\n",
    "from datetime import datetime\n",
    "from typing import List\n",
    "from typing import Optional, Literal, Dict, Any\n",
    "\n",
    "import numpy as np\n",
    "import optuna\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from loguru import logger\n",
    "from pydantic import BaseModel\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n"
   ],
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Recommender deklarieren\n",
    "(Base-Recommender, Collaborative Filtering, Content-Based & Optional noch den Deep-Learning-Recommender)"
   ],
   "id": "1adeaf18e76f57ae"
  },
  {
   "cell_type": "code",
   "id": "813ebe70194fc0a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:40.997897Z",
     "start_time": "2025-06-16T13:08:40.991667Z"
    }
   },
   "source": [
    "class Recommender:\n",
    "    def __init__(self):\n",
    "        self.k = 3 # default\n",
    "        self.user_id = None\n",
    "        self.item_id = None\n",
    "        self.similarity: Literal[\"cosine\", \"pearson\"] = \"cosine\"  # default\n",
    "        self.calculation_variant: Literal[\"weighted\", \"unweighted\"] = \"weighted\"  # default\n",
    "        self.data = None\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def _preprocess_data(self):\n",
    "        ...\n",
    "\n",
    "\n",
    "    def _prepare_information(self, user_id: str, item_id: str, k: int, similarity: Literal[\"cosine\", \"pearson\"] = \"cosine\", calculation_variant: Literal[\"weighted\", \"unweighted\"] = \"weighted\") -> None:\n",
    "        self.user_id = user_id\n",
    "        self.item_id = item_id\n",
    "        self.similarity = similarity\n",
    "        self.calculation_variant = calculation_variant\n",
    "        self.k = k\n",
    "\n",
    "        if similarity == 'pearson' and self.data is not None:\n",
    "            self.data['mean'] = self.data.mean(axis=1)\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(\n",
    "            self,\n",
    "            user_id: str,\n",
    "            item_id: str,\n",
    "            similarity: Optional[Literal['cosine', 'pearson']] = 'cosine',   # only for collaborative filtering\n",
    "            calculation_variety: Optional[Literal['weighted', 'unweighted']] = 'weighted',  # only for collaborative filtering\n",
    "            k: Optional[int] = 3,\n",
    "            second_k_value: Optional[int] = None):\n",
    "        ..."
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "id": "cad50448f6df9a05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:41.051063Z",
     "start_time": "2025-06-16T13:08:41.033578Z"
    }
   },
   "source": [
    "class CollaborativeFilteringRecommender(Recommender):\n",
    "    def __init__(self, data: pd.DataFrame, mode: Literal['user', 'item'] = 'user', display_results_for_each_step: Optional[bool] = False) -> None:\n",
    "        super().__init__()\n",
    "        self.display_results_for_each_step = display_results_for_each_step\n",
    "        self.original_data = data\n",
    "        self.mode = mode\n",
    "        self._preprocess_data()\n",
    "\n",
    "\n",
    "    def _preprocess_data(self) -> None:\n",
    "        self.original_data = self.original_data.set_index(\"user_ID\")\n",
    "        self.original_data.index = self.original_data.index.astype(str) # convert the index to string (due to error with int values)\n",
    "        if self.mode == 'item':\n",
    "            self.data = self.original_data.T  # transpose for item based\n",
    "        else:\n",
    "            self.data = self.original_data  # original for user based\n",
    "\n",
    "\n",
    "    def _calculate_distance_and_indices(self, dataframe: pd.DataFrame) -> ([], []):\n",
    "        knn = NearestNeighbors(metric=\"cosine\", algorithm='brute')\n",
    "        knn.fit(dataframe.values)\n",
    "        distances, indices = knn.kneighbors(dataframe.values, n_neighbors=self.k + 1)\n",
    "\n",
    "        if self.mode == 'item':\n",
    "            index = dataframe.index.get_loc(self.item_id)\n",
    "        else:\n",
    "            index = dataframe.index.get_loc(self.user_id)\n",
    "\n",
    "        similar_distances = distances[index, 1:]\n",
    "        similar_indices = indices[index, 1:]\n",
    "\n",
    "        return similar_distances, similar_indices\n",
    "\n",
    "    def _calculate_similarities(self, similar_distances: np.ndarray) -> np.ndarray:\n",
    "        similarity = [1 - x for x in similar_distances]\n",
    "        similarity = [(y + 1) / 2 for y in similarity]\n",
    "        return np.array(similarity)\n",
    "\n",
    "    def _calculate_result(self, similarity: np.ndarray, ratings: np.ndarray) -> float:\n",
    "        if self.calculation_variant == \"weighted\":\n",
    "            mean = np.dot(ratings, similarity) / similarity.sum()\n",
    "            return mean\n",
    "        else:\n",
    "            return float(np.mean(ratings))\n",
    "\n",
    "    def _check_values(self) -> None:\n",
    "        if self.mode == 'user':\n",
    "            if self.user_id not in self.data.index:\n",
    "                raise ValueError(f\"User {self.user_id} nicht in Daten.\")\n",
    "            if self.item_id not in self.data.columns:\n",
    "                raise ValueError(f\"Item {self.item_id} nicht in Daten.\")\n",
    "        elif self.mode == 'item':\n",
    "            if self.user_id not in self.original_data.index:\n",
    "                raise ValueError(\n",
    "                    f\"User {self.user_id} nicht in Originaldaten.\")\n",
    "            if self.item_id not in self.data.index:\n",
    "                raise ValueError(\n",
    "                    f\"Item {self.item_id} nicht in transponierten Daten.\")\n",
    "\n",
    "    def _process_item_based(self) -> pd.DataFrame:\n",
    "        user_ratings = self.original_data.loc[self.user_id]\n",
    "\n",
    "        # filter based on the item. Only the users that already gave a rating are relevant\n",
    "        rated_items = user_ratings[user_ratings > 0.0].index.tolist()\n",
    "\n",
    "        if not rated_items:\n",
    "            raise ValueError(f\"User {self.user_id} hat keine Items bewertet!\")\n",
    "\n",
    "        return self.data.loc[rated_items + [self.item_id]]\n",
    "\n",
    "    def _process_user_based(self) -> pd.DataFrame:\n",
    "        # filter based on the item. Only the users that already gave a rating are relevant\n",
    "        relevant_df = self.data[self.data[self.item_id] > 0.0]\n",
    "\n",
    "        # add the user we are looking for (due to non-existing rating this user where filtered out)\n",
    "        return pd.concat([relevant_df, self.data.loc[[self.user_id]]])\n",
    "\n",
    "    def _normalize_for_pearson(self, relevant_df: pd.DataFrame) -> pd.DataFrame:\n",
    "        mean_values = relevant_df.mean(axis=1).to_numpy()\n",
    "        relevant_df = relevant_df.sub(mean_values, axis=0)\n",
    "        return relevant_df\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            user_id: str,\n",
    "            item_id: str,\n",
    "            similarity: Literal['cosine', 'pearson'] = 'cosine',\n",
    "            calculation_variety: Literal['weighted', 'unweighted'] = 'weighted',\n",
    "            k: Optional[int] = 3,\n",
    "            second_k_value: Optional[int] = None) -> float:\n",
    "        self._prepare_information(user_id=user_id, item_id=item_id, similarity=similarity, calculation_variant=calculation_variety, k=k)\n",
    "        self._check_values()\n",
    "\n",
    "        if self.mode == 'item':\n",
    "            relevant_df = self._process_item_based()\n",
    "        else:\n",
    "            relevant_df = self._process_user_based()\n",
    "\n",
    "        if similarity == 'pearson':\n",
    "            self._normalize_for_pearson(relevant_df)\n",
    "\n",
    "        # make sure that there are no NaN values -> set NaN to 0.0\n",
    "        relevant_df = relevant_df.fillna(0.0)\n",
    "        similar_distances, similar_indices = self._calculate_distance_and_indices(dataframe=relevant_df)\n",
    "\n",
    "        if self.mode == 'item':\n",
    "            ratings = relevant_df.iloc[similar_indices][self.user_id].to_numpy()\n",
    "        else:\n",
    "            ratings = relevant_df.iloc[similar_indices][self.item_id].to_numpy()\n",
    "\n",
    "        similarity = self._calculate_similarities(similar_distances)\n",
    "        result = self._calculate_result(similarity, ratings)\n",
    "\n",
    "        if self.display_results_for_each_step:\n",
    "          self.explain(similar_indices, relevant_df, ratings, similarity, result)\n",
    "\n",
    "        return result\n",
    "\n",
    "    def explain(self, similar_indices, relevant_df, ratings, similarity, result) -> None:\n",
    "        print(\"-\" * 50)\n",
    "        print(f\"<mode: {self.mode}>\")\n",
    "        print(f\"({self.calculation_variant}) Mittelwert: {result:.4f}\")\n",
    "        print(f\"Metrik: {self.similarity}\")\n",
    "        print()\n",
    "        print(f\"k ({self.k}) Ã¤hnlichsten {'Items' if self.mode == 'item' else 'Nutzer'}:\")\n",
    "        df = pd.DataFrame({\n",
    "            \"ID\": relevant_df.index[similar_indices],\n",
    "            \"rating\": ratings,\n",
    "            \"similarity\": similarity\n",
    "        }).reset_index(drop=True)\n",
    "        print(df.to_string(index=True, header=True))\n",
    "        print(\"-\" * 50)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "id": "6928825fe8030222",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:41.085497Z",
     "start_time": "2025-06-16T13:08:41.066018Z"
    }
   },
   "source": [
    "class ContentBasedRecommender(Recommender):\n",
    "    def __init__(self, item_profile: pd.DataFrame, user_ratings: pd.DataFrame) -> None:\n",
    "        super().__init__()\n",
    "        self.item_profile = item_profile\n",
    "        self.user_ratings = user_ratings\n",
    "        self.k = 3\n",
    "        self.feature_matrix = None\n",
    "        self._preprocess_data()\n",
    "\n",
    "        # check if the features \"budget\", \"revenue\", \"runtime\" are relevant for the item/rating correlation\n",
    "        self._check_features_correlation(features=[\"budget\", \"revenue\", \"runtime\"])\n",
    "        self._calculate_tfidf_matrix()\n",
    "\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        self.item_profile[\"item_ID\"] = self.item_profile[\"item_ID\"].astype(str)\n",
    "        self.user_ratings[\"item_ID\"] = self.user_ratings[\"item_ID\"].astype(str)\n",
    "        self.user_ratings[\"user_ID\"] = self.user_ratings[\"user_ID\"].astype(str)\n",
    "\n",
    "    def _check_features_correlation(self, features: List[str]) -> None:\n",
    "        irrelevant_features = []  #  list for irrelevant feature that will be removed\n",
    "\n",
    "        for feature in features:\n",
    "            if feature not in self.item_profile.columns:\n",
    "                continue\n",
    "\n",
    "            # combine item and user ratings\n",
    "            merged_data = pd.merge(self.user_ratings, self.item_profile, on=\"item_ID\")\n",
    "\n",
    "            # convert to numeric\n",
    "            feature_data = pd.to_numeric(merged_data[feature].fillna(0), errors=\"coerce\")\n",
    "            rating_data = pd.to_numeric(merged_data[\"rating\"].fillna(0), errors=\"coerce\")\n",
    "\n",
    "            # calculate the correlation between the user rating and the feature\n",
    "            correlation, p_value = stats.pearsonr(feature_data, rating_data)\n",
    "\n",
    "            # check if the correlation is relevant / significant\n",
    "            if abs(correlation) < 0.1 or p_value > 0.05:\n",
    "                logger.debug(f\"Feature '{feature}' does not have a sigificant correlation and will be ignored.\")\n",
    "                irrelevant_features.append(feature)\n",
    "            else:\n",
    "                logger.debug(f\"Feature '{feature}' has a significant correlation: {correlation}\")\n",
    "\n",
    "        self.item_profile.drop(columns=irrelevant_features, inplace=True)\n",
    "\n",
    "\n",
    "    def _safe_get_feature(self, feature_name):\n",
    "        if feature_name in self.item_profile.columns:\n",
    "            return self.item_profile[feature_name]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def _calculate_tfidf_matrix(self) -> None:\n",
    "        # optional but if the title is empty we set it as an empty string\n",
    "        self.item_profile[\"title\"] = self.item_profile[\"title\"].fillna(\"\")\n",
    "\n",
    "        # use the TfidfVectorizer() to transform title into numerical feature\n",
    "        title_vectorizer = TfidfVectorizer()\n",
    "        title_features = title_vectorizer.fit_transform(self.item_profile[\"title\"])\n",
    "\n",
    "        # change genre columns in text by just extracting the word after '\"Genre_\"'\n",
    "        genre_cols = [col for col in self.item_profile.columns if col.startswith(\"Genre_\")]\n",
    "        if genre_cols:\n",
    "            self.item_profile[\"genre_text\"] = self.item_profile[genre_cols].astype(int).apply(\n",
    "                lambda row: \" \".join([col.replace(\"Genre_\", \"\") for col, val in row.items() if val == 1]), axis=1\n",
    "            )\n",
    "            genre_vectorizer = TfidfVectorizer()\n",
    "            genre_features = genre_vectorizer.fit_transform(self.item_profile[\"genre_text\"])\n",
    "        else:\n",
    "            genre_features = np.empty((len(self.item_profile), 0))\n",
    "\n",
    "        # the language of the items transformed into one-hot-encoded-dummies\n",
    "        language_dummies = pd.get_dummies(self.item_profile[\"original_language\"], prefix=\"lang\")\n",
    "\n",
    "        # put runtime into three categories (short, medium, long)\n",
    "        runtime_feature = self._safe_get_feature(\"runtime\")\n",
    "        if runtime_feature is not None:\n",
    "            runtime_bucket = pd.qcut(runtime_feature, q=3, labels=[\"kurz\", \"mittel\", \"lang\"])\n",
    "            runtime_dummies = pd.get_dummies(runtime_bucket, prefix=\"runtime\")\n",
    "        else:\n",
    "            runtime_dummies = pd.DataFrame(index=self.item_profile.index)\n",
    "\n",
    "        # budget and include will be logarithmically transformed and then scaled\n",
    "        numerical_features = []\n",
    "        if \"budget\" in self.item_profile.columns:\n",
    "            self.item_profile[\"log_budget\"] = np.log1p(self.item_profile[\"budget\"].fillna(0))\n",
    "            numerical_features.append(\"log_budget\")\n",
    "        if \"revenue\" in self.item_profile.columns:\n",
    "            self.item_profile[\"log_revenue\"] = np.log1p(self.item_profile[\"revenue\"].fillna(0))\n",
    "            numerical_features.append(\"log_revenue\")\n",
    "\n",
    "        if numerical_features:\n",
    "            scaler = StandardScaler()\n",
    "            scaled_numericals = scaler.fit_transform(self.item_profile[numerical_features])\n",
    "        else:\n",
    "            scaled_numericals = np.empty((len(self.item_profile), 0))\n",
    "\n",
    "        # create feature matrix\n",
    "        self.feature_matrix = hstack([\n",
    "            title_features,\n",
    "            genre_features,\n",
    "            language_dummies.values,\n",
    "            runtime_dummies.values,\n",
    "            scaled_numericals\n",
    "        ])\n",
    "\n",
    "        self.feature_matrix = csr_matrix(self.feature_matrix)\n",
    "\n",
    "    def _check_values(self):\n",
    "        if self.user_id not in self.user_ratings[\"user_ID\"].values:\n",
    "            raise ValueError(f\"User-ID {self.user_id} not found.\")\n",
    "\n",
    "        if self.item_id not in self.item_profile[\"item_ID\"].values:\n",
    "            raise ValueError(f\"Item-ID {self.item_id} not found.\")\n",
    "\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            user_id: str,\n",
    "            item_id: str,\n",
    "            similarity: Optional[Literal['cosine', 'pearson']] = 'cosine',  # only for collaborative filtering\n",
    "            calculation_variety: Optional[Literal['weighted', 'unweighted']] = 'weighted', # only for collaborative filtering\n",
    "            k: Optional[int] = 3,\n",
    "            second_k_value: Optional[int] = None) -> float:\n",
    "\n",
    "        # default function to save all the information\n",
    "        self._prepare_information(user_id=user_id, item_id=item_id, k=k)\n",
    "\n",
    "        # check if the values included in the dataframes\n",
    "        self._check_values()\n",
    "\n",
    "        # extract only the items, the user rated\n",
    "        rated_items = self.user_ratings[self.user_ratings[\"user_ID\"] == user_id]\n",
    "        rated_item_ids = rated_items[\"item_ID\"].values\n",
    "\n",
    "        # this case can happen when k is greater than the rated items by the user\n",
    "        if self.k > len(rated_item_ids):\n",
    "            self.k = len(rated_item_ids)\n",
    "\n",
    "        # extract the rated item indices from the item profile\n",
    "        rated_item_indices = self.item_profile[self.item_profile[\"item_ID\"].isin(rated_item_ids)].index\n",
    "\n",
    "        # check if the user rated some items... if not then return 0.0\n",
    "        if len(rated_item_indices) == 0:\n",
    "            return 0.0\n",
    "\n",
    "        # get the feature matrix that is calculated in the '_calculate_tfidf_matrix()'-Method\n",
    "        filtered_matrix = self.feature_matrix[rated_item_indices]\n",
    "\n",
    "        # default kNN usage like in the lecture with brute algorithm and cosine as metric\n",
    "        knn = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
    "        knn.fit(filtered_matrix)\n",
    "\n",
    "        item_index = self.item_profile[self.item_profile[\"item_ID\"] == item_id].index[0]\n",
    "        distances, indices = knn.kneighbors(self.feature_matrix[item_index], n_neighbors=self.k + 1)  # k+1 because the item itself is also included\n",
    "\n",
    "        # the similar item indices beginning with the first real neighbor\n",
    "        similar_items = indices.flatten()[1:]\n",
    "        similar_item_indices = rated_item_indices[similar_items]\n",
    "\n",
    "        # extract for each item in the similar item indices list the rating and save it in the list\n",
    "        similar_ratings = []\n",
    "        for idx in similar_item_indices:\n",
    "            similar_item_id = self.item_profile.iloc[idx][\"item_ID\"]\n",
    "            user_rating = self.user_ratings[(self.user_ratings[\"user_ID\"] == user_id) & (self.user_ratings[\"item_ID\"] == similar_item_id)]\n",
    "            if not user_rating.empty:\n",
    "                similar_ratings.append(user_rating[\"rating\"].values[0])\n",
    "\n",
    "        # if the similar ratings is zero then we return a default 0.0\n",
    "        if not similar_ratings:\n",
    "            return 0.0\n",
    "\n",
    "        # calculate the predicted rating based on the sum of ratings and len of ratings\n",
    "        return sum(similar_ratings) / len(similar_ratings)"
   ],
   "outputs": [],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "id": "c8fbff7bb11954ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:41.126511Z",
     "start_time": "2025-06-16T13:08:41.120221Z"
    }
   },
   "source": [
    "class HybridRecommender(Recommender):\n",
    "    def __init__(self, data: pd.DataFrame, item_profile: pd.DataFrame, user_ratings: pd.DataFrame, mode: Literal['user', 'item'] = 'user', alpha: float = 0.5):\n",
    "        super().__init__()\n",
    "        self.collaborative_recommender = CollaborativeFilteringRecommender(data=data, mode=mode)\n",
    "        self.content_based_recommender = ContentBasedRecommender(item_profile=item_profile, user_ratings=user_ratings)\n",
    "        self.alpha = alpha\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            user_id: str,\n",
    "            item_id: str,\n",
    "            similarity: Optional[Literal['cosine', 'pearson']] = 'cosine',  # only for collaborative filtering\n",
    "            calculation_variety: Optional[Literal['weighted', 'unweighted']] = 'weighted', # only for collaborative filtering\n",
    "            k: Optional[int] = 3,\n",
    "            second_k_value: Optional[int] = 3):\n",
    "\n",
    "        collaborative_prediction = self.collaborative_recommender.predict(\n",
    "            user_id=user_id,\n",
    "            item_id=item_id,\n",
    "            similarity=similarity, # ignore that it can be NONE\n",
    "            calculation_variety=calculation_variety, # ignore that it can be NONE\n",
    "            k=k\n",
    "        )\n",
    "\n",
    "        content_based_prediction = self.content_based_recommender.predict(\n",
    "            user_id=user_id,\n",
    "            item_id=item_id,\n",
    "            similarity=similarity,\n",
    "            calculation_variety=calculation_variety,\n",
    "            k=second_k_value\n",
    "        )\n",
    "\n",
    "        # combine both with alpha as weight\n",
    "        combined_prediction = (self.alpha * collaborative_prediction) + ((1 - self.alpha) * content_based_prediction)\n",
    "        return combined_prediction"
   ],
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "d160643fb14f6b77"
  },
  {
   "cell_type": "markdown",
   "id": "be84f149",
   "metadata": {},
   "source": "`OPTIONAL`  Deep-Learning-Recomender"
  },
  {
   "cell_type": "code",
   "id": "dfc14af51f24d030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:41.178907Z",
     "start_time": "2025-06-16T13:08:41.146145Z"
    }
   },
   "source": [
    "# Dataset class to handle user-item-rating data\n",
    "class RatingsDataset(Dataset):\n",
    "    def __init__(self, data: pd.DataFrame):\n",
    "        # Convert user, item, and rating columns to tensors\n",
    "        self.u = torch.tensor(data[\"user_idx\"].values, dtype=torch.long)\n",
    "        self.i = torch.tensor(data[\"item_idx\"].values, dtype=torch.long)\n",
    "        self.r = torch.tensor(data[\"rating\"].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the number of samples in the dataset\n",
    "        return len(self.r)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Return a single sample (user, item, rating) by index\n",
    "        return self.u[idx], self.i[idx], self.r[idx]\n",
    "\n",
    "\n",
    "# hybrid matrix factorization model\n",
    "class HybridMF(nn.Module):\n",
    "    def __init__(self, num_users: int, num_items: int, embedding_dim: int, item_features, dropout: float = 0.15):\n",
    "        super().__init__()\n",
    "        # Embedding layers for users and items (Embedding-layer is one layer in the neral network (vectors))\n",
    "        self.P = nn.Embedding(num_users, embedding_dim)\n",
    "        self.Q = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "        # Bias terms for users and items (representate individual variances... e.g one user can generally give better ratings as default)\n",
    "        self.bu = nn.Embedding(num_users, 1)\n",
    "        self.bi = nn.Embedding(num_items, 1)\n",
    "\n",
    "        # Global bias term (reprentate the average variance over the complete dataset)\n",
    "        self.mu = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "        # Linear layer to project item features into the latent space (to combine them with the embeddings of the items)\n",
    "        self.F = nn.Linear(item_features.shape[1], embedding_dim, bias=False)\n",
    "\n",
    "        # Register item features as a buffer (non-trainable parameter)\n",
    "        self.register_buffer(\"item_features\", item_features)\n",
    "\n",
    "        # Dropout layer for regularization\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "\n",
    "        # Initialize weights for embeddings and linear layer\n",
    "        nn.init.normal_(self.P.weight, std=0.05)\n",
    "        nn.init.normal_(self.Q.weight, std=0.05)\n",
    "        nn.init.xavier_uniform_(self.F.weight)\n",
    "\n",
    "    def forward(self, u, i):\n",
    "        # Compute item latent factors by combining embeddings and projected features\n",
    "        q = self.Q(i) + self.F(self.item_features[i])\n",
    "        q = self.drop(q)\n",
    "\n",
    "        # Compute the predicted rating\n",
    "        return (self.P(u) * q).sum(-1) + self.mu + self.bu(u).squeeze() + self.bi(i).squeeze()\n",
    "\n",
    "\n",
    "class DeepLearningRecommender:\n",
    "    def __init__(\n",
    "            self,\n",
    "            trainingdata: pd.DataFrame,\n",
    "            item_profile: pd.DataFrame,\n",
    "            testdata: pd.DataFrame,\n",
    "            embedding_dim=64,\n",
    "            batch_size=1024,\n",
    "            epochs=60,\n",
    "            lr=1e-3,\n",
    "            weight_decay=3e-5,\n",
    "            dropout_p=0.2,\n",
    "            early_stopping_rounds=10\n",
    "    ) -> None:\n",
    "\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr  # learning rate\n",
    "        self.weight_decay = weight_decay\n",
    "        self.dropout_p = dropout_p\n",
    "        self.early_stopping_rounds = early_stopping_rounds\n",
    "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "        # Prepare data and build the model\n",
    "        self.train_data, self.val_data, self.feat_mat, self.global_mean = self._prepare_data(trainingdata, item_profile, testdata)\n",
    "        self.model = self._build_model()\n",
    "        self.fit()\n",
    "\n",
    "    def _prepare_data(self, trainingdata, item_profile, testdata):\n",
    "        # Convert user and item ids to strings\n",
    "        trainingdata[[\"user_ID\", \"item_ID\"]] = trainingdata[[\"user_ID\", \"item_ID\"]].astype(str)\n",
    "        testdata[[\"user_ID\", \"item_ID\"]] = testdata[[\"user_ID\", \"item_ID\"]].astype(str)\n",
    "\n",
    "        # Create mappings from user/item ids to indices\n",
    "        self.user2idx = {u: i for i, u in enumerate(trainingdata[\"user_ID\"].unique())}\n",
    "        self.item2idx = {m: j for j, m in enumerate(trainingdata[\"item_ID\"].unique())}\n",
    "\n",
    "        # Map user and item ids to the indices in training and test data (both needed)\n",
    "        for df in [trainingdata, testdata]:\n",
    "            df[\"user_idx\"] = df[\"user_ID\"].map(self.user2idx)\n",
    "            df[\"item_idx\"] = df[\"item_ID\"].map(self.item2idx)\n",
    "\n",
    "        # filter and process item features\n",
    "        ip = item_profile[item_profile[\"item_ID\"].isin(self.item2idx)].copy()\n",
    "        ip[\"item_idx\"] = ip[\"item_ID\"].map(self.item2idx)\n",
    "        ip.sort_values(\"item_idx\", inplace=True)\n",
    "        feat_df = ip.filter(regex=\"^Genre_\")\n",
    "\n",
    "        # scale feature or set placeholder if no feature\n",
    "        if not feat_df.empty:\n",
    "            feat_df = StandardScaler().fit_transform(feat_df.fillna(0))\n",
    "        else:\n",
    "            feat_df = np.zeros((len(self.item2idx), 1))\n",
    "\n",
    "        # convert features to a tensor (array in a dimension you need, vgl. Skalar (5), Vektor ([1,2,3]), ...)\n",
    "        feat_mat = torch.tensor(feat_df, dtype=torch.float32)\n",
    "\n",
    "        # Compute the global mean rating... optional but whats the ase when user or item i unknown ? (vgl. cold-start-szenario)\n",
    "        global_mean = trainingdata[\"rating\"].mean()\n",
    "\n",
    "        # Create data loaders for training and validation (Dataloaders take the work of batching, shuffle or parallel loading to improve training)\n",
    "        train_loader = DataLoader(RatingsDataset(trainingdata), batch_size=self.batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(RatingsDataset(testdata), batch_size=self.batch_size)\n",
    "\n",
    "        return train_loader, val_loader, feat_mat, global_mean\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Build the hybrid matrix factorization model\n",
    "        return HybridMF(\n",
    "            num_users=len(self.train_data.dataset.u.unique()),\n",
    "            num_items=len(self.train_data.dataset.i.unique()),\n",
    "            embedding_dim=self.embedding_dim,\n",
    "            item_features=self.feat_mat,\n",
    "            dropout=self.dropout_p,\n",
    "        ).to(self.device)\n",
    "\n",
    "    def fit(self):\n",
    "        # Initialize optimizer and learning rate scheduler\n",
    "        opt = optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3)\n",
    "        best_mae, epochs_no_imp = float(\"inf\"), 0\n",
    "        best_model_state = None  # Variable to store the best model state\n",
    "\n",
    "        # Training loop ... as we discussed in the lecture\n",
    "        for ep in range(1, self.epochs + 1):\n",
    "            self.model.train()\n",
    "            epoch_loss = 0\n",
    "            for u, i, r in self.train_data:\n",
    "                u, i, r = u.to(self.device), i.to(self.device), r.to(self.device)\n",
    "                opt.zero_grad()\n",
    "                loss = nn.functional.smooth_l1_loss(self.model(u, i), r, beta=1.0)  # Feed-Forward\n",
    "                loss.backward()  # Backpropagation\n",
    "                opt.step()\n",
    "                epoch_loss += loss.item()  # collect the loss-value\n",
    "\n",
    "\n",
    "            # Calculate validation-Loss (we need the smallest MAE possible)\n",
    "            val_mae = self.evaluate_loader(self.val_data)\n",
    "            # Print average loss and MAE of each epoch\n",
    "            logger.debug(f\"Epoche {ep}\\t| Training Loss: {epoch_loss / len(self.train_data)} \\t| Validation MAE: {val_mae}\")\n",
    "            scheduler.step(val_mae)\n",
    "\n",
    "            # Save the best model\n",
    "            if val_mae < best_mae:\n",
    "                best_mae, epochs_no_imp = val_mae, 0\n",
    "                best_model_state = self.model.state_dict()\n",
    "            else:\n",
    "                epochs_no_imp += 1\n",
    "                if epochs_no_imp >= self.early_stopping_rounds:\n",
    "                    break\n",
    "\n",
    "        # Load the best model state from memory\n",
    "        if best_model_state is not None:\n",
    "            self.model.load_state_dict(best_model_state)\n",
    "\n",
    "\n",
    "    def evaluate_loader(self, loader):\n",
    "        # Evaluate the model on a data loader\n",
    "        self.model.eval()\n",
    "        err, n = 0.0, 0\n",
    "        with torch.no_grad():\n",
    "            for u, i, r in loader:\n",
    "                preds = self.model(u.to(self.device), i.to(self.device)).cpu()\n",
    "                err += torch.abs(preds - r).sum().item()\n",
    "                n += len(r)\n",
    "        return err / n\n",
    "\n",
    "    def predict(self, user_id, item_id):\n",
    "        # Convert user and item IDs to indices\n",
    "        user_idx = self.user2idx.get(user_id)\n",
    "        item_idx = self.item2idx.get(item_id)\n",
    "\n",
    "        # Handle cold-start cases\n",
    "        if user_idx is None and item_idx is None:\n",
    "            return float(self.global_mean)\n",
    "\n",
    "        if user_idx is None:\n",
    "            item_bias = self.model.bi.weight[item_idx].item()\n",
    "            return float(np.clip(self.global_mean + item_bias, 0.0, 5.0)) # clip ensures that the value is between 0 and 5\n",
    "\n",
    "        if item_idx is None:\n",
    "            user_bias = self.model.bu.weight[user_idx].item()\n",
    "            return float(np.clip(self.global_mean + user_bias, 0.0, 5.0)) # clip ensures that the value is between 0 and 5\n",
    "\n",
    "        # Compute the predicted rating\n",
    "        u = torch.tensor([user_idx], device=self.device)\n",
    "        i = torch.tensor([item_idx], device=self.device)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            score = self.model(u, i).item()\n",
    "        return float(np.clip(score, 0.0, 5.0)) # clip ensures that the value is between 0 and 5\n",
    "\n",
    "\n",
    "\n",
    "class HyperparamOptimizedDeepLearningRecommender(Recommender):\n",
    "    def __init__(self, testdata: pd.DataFrame, item_profile: pd.DataFrame, trainingdata: pd.DataFrame, include_hyperparam_check: Optional[bool] = False):\n",
    "        super().__init__()\n",
    "        self.testdata = testdata\n",
    "        self.item_profile = item_profile\n",
    "        self.trainingdata = trainingdata\n",
    "\n",
    "        self.include_hyperparam_check= include_hyperparam_check\n",
    "        self.recommender = None\n",
    "\n",
    "\n",
    "    def _preprocess_data(self):\n",
    "        # this will be done in the used recommender class\n",
    "        pass\n",
    "\n",
    "    def _objective(self, trial):\n",
    "        embedding_dim = trial.suggest_int(\"embedding_dim\", 32, 128, step=16)\n",
    "        batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
    "        lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
    "        dropout_p = trial.suggest_uniform(\"dropout_p\", 0.1, 0.5)\n",
    "        weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3)\n",
    "\n",
    "        optimize_recommender = DeepLearningRecommender(\n",
    "            trainingdata=self.trainingdata,\n",
    "            item_profile=self.item_profile,\n",
    "            testdata=self.testdata,\n",
    "            embedding_dim=embedding_dim,\n",
    "            batch_size=batch_size,\n",
    "            lr=lr,\n",
    "            dropout_p=dropout_p,\n",
    "            weight_decay=weight_decay,\n",
    "        )\n",
    "\n",
    "        val_mae = optimize_recommender.evaluate_loader(optimize_recommender.val_data)\n",
    "        return val_mae\n",
    "\n",
    "    def _build_recommender(self, params: dict) -> None:\n",
    "        self.recommender = DeepLearningRecommender(\n",
    "            trainingdata=self.trainingdata,\n",
    "            item_profile=self.item_profile,\n",
    "            testdata=self.testdata,\n",
    "            embedding_dim=params[\"embedding_dim\"],\n",
    "            batch_size=params[\"batch_size\"],\n",
    "            lr=params[\"lr\"],\n",
    "            dropout_p=params[\"dropout_p\"],\n",
    "            weight_decay=params[\"weight_decay\"],\n",
    "        )\n",
    "\n",
    "    def _find_out_best_params(self) -> Dict[str, Any]:\n",
    "        study = optuna.create_study(direction=\"minimize\")\n",
    "        study.optimize(self._objective, n_trials=50)\n",
    "\n",
    "        print(\"Beste Parameter:\", study.best_params)\n",
    "\n",
    "        return study.best_params\n",
    "\n",
    "\n",
    "    def predict(\n",
    "            self,\n",
    "            user_id: str,\n",
    "            item_id: str,\n",
    "            similarity: Optional[Literal['cosine', 'pearson']] = 'cosine',\n",
    "            calculation_variety: Optional[Literal['weighted', 'unweighted']] = 'weighted',\n",
    "            k: Optional[int] = 3,\n",
    "            second_k_value: Optional[int] = None,\n",
    "    ) -> float:\n",
    "\n",
    "        if self.include_hyperparam_check:\n",
    "            best_params = self._find_out_best_params()\n",
    "        else:\n",
    "            # values came from our test with the hyperparam check\n",
    "            best_params = {\n",
    "                \"lr\": 0.00483293357554159,\n",
    "                \"embedding_dim\": 32,\n",
    "                \"dropout_p\": 0.24090306736140638,\n",
    "                \"weight_decay\": 0.00022232253823222672,\n",
    "                \"batch_size\": 64,\n",
    "            }\n",
    "\n",
    "\n",
    "        if self.recommender is None:\n",
    "            self._build_recommender(best_params)\n",
    "\n",
    "        return self.recommender.predict(user_id, item_id)"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "333ff78ed02f42f6"
  },
  {
   "cell_type": "markdown",
   "id": "f36958e4",
   "metadata": {},
   "source": [
    "## MAE Tester\n",
    "Verwendet, um die verschiedenen Recommender zu Evaluieren und anhand des MAEs zu vergleichen"
   ]
  },
  {
   "cell_type": "code",
   "id": "bd623ba6223a9825",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:41.238187Z",
     "start_time": "2025-06-16T13:08:41.214967Z"
    }
   },
   "source": [
    "class Test(BaseModel):\n",
    "    name: str\n",
    "    type: Literal[\"collaborative_filtering\", \"content_based\", \"hybrid\", \"deep_learning\"]\n",
    "    mode: Optional[Literal[\"user\", \"item\"]] = \"item\"\n",
    "    k_value: Optional[int] = 3\n",
    "    second_k_value: Optional[int] = 3\n",
    "    metric: Optional[Literal[\"cosine\", \"pearson\"]] = 'cosine'\n",
    "    calculation_variety: Optional[Literal[\"weighted\", \"unweighted\"]] = 'weighted'\n",
    "    alpha: Optional[float] = 0.5\n",
    "\n",
    "\n",
    "class TestResult(BaseModel):\n",
    "    name: str\n",
    "    type: Literal[\"collaborative_filtering\", \"content_based\", \"hybrid\", \"deep_learning\"]\n",
    "    mode: Literal[\"user\", \"item\"] | None\n",
    "    k_value: int | None\n",
    "    second_k_value: int | None\n",
    "    metric: Literal[\"cosine\", \"pearson\"] | None\n",
    "    calculation_variety: Literal[\"weighted\", \"unweighted\"] | None\n",
    "    alpha: float | None\n",
    "    mae: float\n",
    "\n",
    "\n",
    "class TestResults(BaseModel): # just for saving in a \"pretty\" form\n",
    "    date: str\n",
    "    num_tests: int\n",
    "    best_test: TestResult\n",
    "    results: List[TestResult]\n",
    "\n",
    "\n",
    "\n",
    "class MAETester:\n",
    "    def __init__(self, tests: List[Test], test_data_path: str, data_path: str, item_profile_path: str, ratings: str):\n",
    "        self.tests = tests\n",
    "        self.testdata = pd.read_csv(test_data_path)  # testdata (for evaluaton)\n",
    "        self.item_profile = pd.read_csv(item_profile_path)\n",
    "        self.user_ratings = pd.read_csv(ratings)\n",
    "        self._prepare_data()\n",
    "        self.data = pd.read_csv(data_path)  # trainings-data\n",
    "        self.results: List[TestResult] = []\n",
    "\n",
    "\n",
    "    def _prepare_data(self):\n",
    "        self.testdata[\"user_ID\"] = self.testdata[\"user_ID\"].astype(str)\n",
    "        self.testdata[\"item_ID\"] = self.testdata[\"item_ID\"].astype(str)\n",
    "\n",
    "    # because we only have 0.5 steps in testdata\n",
    "    @staticmethod\n",
    "    def _round_to_nearest_half(value: float):\n",
    "        return round(value * 2) / 2\n",
    "\n",
    "    def run_tests(self) -> pd.DataFrame:\n",
    "        for test in self.tests:\n",
    "            result = self._run_test(test)\n",
    "            self.results.append(result)\n",
    "            logger.success(f\"Test abgeschlossen: {test.name}, MAE: {result.mae:.4f}\\n\")\n",
    "\n",
    "        # display final resultse\n",
    "        result_df = self._summarize_test_results()\n",
    "\n",
    "        # save final results to file\n",
    "        self._save_to_file()\n",
    "\n",
    "        return result_df\n",
    "\n",
    "    def _run_test(self, test: Test) -> TestResult:\n",
    "        logger.info(f\"Running test: {test.name}\")\n",
    "\n",
    "        if test.type == \"content_based\":\n",
    "            recommender = ContentBasedRecommender(\n",
    "                item_profile=self.item_profile,\n",
    "                user_ratings=self.user_ratings,\n",
    "            )\n",
    "        elif test.type == \"collaborative_filtering\":\n",
    "            recommender = CollaborativeFilteringRecommender(\n",
    "                mode=test.mode, # ignore type (that this can be NONE)\n",
    "                data=self.data,\n",
    "            )\n",
    "        elif test.type == \"hybrid\":\n",
    "            recommender = HybridRecommender(\n",
    "                data=self.data,\n",
    "                item_profile=self.item_profile,\n",
    "                user_ratings=self.user_ratings,\n",
    "                mode=test.mode,  # ignore type (that this can be NONE)\n",
    "                alpha=test.alpha,\n",
    "            )\n",
    "        elif test.type == \"deep_learning\":\n",
    "            recommender = HyperparamOptimizedDeepLearningRecommender(\n",
    "                trainingdata=self.user_ratings,\n",
    "                item_profile=self.item_profile,\n",
    "                testdata=self.testdata,\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unbekannter Recomendertyp: {test.type}\")\n",
    "\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "\n",
    "        testdata_list = self.testdata.to_numpy()\n",
    "\n",
    "        for row in tqdm(testdata_list, desc=\"Vorhersagen werden berechnet\"):\n",
    "            user_id: str = str(row[0])\n",
    "            item_id: str = str(row[1])\n",
    "            actual_rating = row[2]\n",
    "\n",
    "            try:\n",
    "                predicted_rating = recommender.predict(\n",
    "                    user_id=user_id,\n",
    "                    item_id=item_id,\n",
    "                    similarity=test.metric,\n",
    "                    calculation_variety=test.calculation_variety,\n",
    "                    k=test.k_value,\n",
    "                    second_k_value=test.second_k_value,\n",
    "                )\n",
    "\n",
    "                predicted_rating = self._round_to_nearest_half(value=predicted_rating)\n",
    "\n",
    "                predictions.append(predicted_rating)\n",
    "                actuals.append(actual_rating)\n",
    "            except ValueError as e:\n",
    "                logger.warning(f\"Fehler bei der Vorhersage: {e}\")\n",
    "\n",
    "        mae = self._mean_absolute_error(actuals, predictions)\n",
    "\n",
    "        return TestResult(\n",
    "            name=test.name,\n",
    "            type=test.type,\n",
    "            mode=test.mode,\n",
    "            k_value=test.k_value,\n",
    "            metric=test.metric,\n",
    "            calculation_variety=test.calculation_variety,\n",
    "            alpha=test.alpha,\n",
    "            second_k_value=test.second_k_value,\n",
    "            mae=mae,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _mean_absolute_error(actuals: List[float], predictions: List[float]) -> float:\n",
    "        if not actuals or not predictions or len(actuals) != len(predictions):\n",
    "            raise ValueError(\"Listen fÃ¼r tatsÃ¤chliche und vorhergesagte Werte mÃ¼ssen gleich lang und nicht leer sein.\")\n",
    "\n",
    "        absolute_errors = [abs(a - p) for a, p in zip(actuals, predictions)]\n",
    "        mae = sum(absolute_errors) / len(absolute_errors)\n",
    "        return mae\n",
    "\n",
    "    def _summarize_test_results(self) -> pd.DataFrame:\n",
    "        if not self.results:\n",
    "            logger.info(\"Keine Testergebnisse vorhanden.\")\n",
    "            return\n",
    "\n",
    "        summary_df = pd.DataFrame([{\n",
    "            \"Testname\": result.name,\n",
    "            \"Recomendertyp\": result.type,\n",
    "            \"Modus\": result.mode if result.type == \"collaborative_filtering\" else \"/\",\n",
    "            \"k-Wert\": \"/\" if result.type == \"deep_learning\" else result.k_value,\n",
    "            \"Metrik\": result.metric if result.type == \"collaborative_filtering\" else \"/\",\n",
    "            \"Berechnungsvariante\": result.calculation_variety if result.type == \"collaborative_filtering\" else \"/\",\n",
    "            \"Alpha (weight)\": result.alpha if result.type == \"hybrid\" else \"/\",\n",
    "            \"MAE\": result.mae\n",
    "        } for result in self.results])\n",
    "\n",
    "        print(\"-\" * 50)\n",
    "        print(\"Zusammenfassung der Testergebnisse:\")\n",
    "        print(summary_df.to_string(index=False))\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        return summary_df\n",
    "\n",
    "\n",
    "    def _save_to_file(self) -> None:\n",
    "        if not self.results:\n",
    "            logger.info(\"Keine Testergebnisse vorhanden, nichts zu speichern.\")\n",
    "            return\n",
    "        date = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        best_test = min(self.results, key=lambda result: result.mae)  # best results based on mae\n",
    "        test_results = TestResults(\n",
    "            date=date,\n",
    "            num_tests=len(self.results),\n",
    "            best_test=best_test,\n",
    "            results=self.results\n",
    "        )\n",
    "\n",
    "        file_path = f\"./outputs/testergebnis_{date.replace(':', '-')}.json\"\n",
    "\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "            json_file.write(test_results.model_dump_json(indent=4))\n",
    "\n",
    "        logger.success(f\"Testergebnisse erfolgreich gespeichert.\")\n"
   ],
   "outputs": [],
   "execution_count": 22
  },
  {
   "cell_type": "markdown",
   "id": "d924f474e12c71d9",
   "metadata": {},
   "source": [
    "# Beginn der Aufrufe und Nutzung der Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af79d55b715866d",
   "metadata": {},
   "source": [
    "Wir haben viele TestfÃ¤lle durchgefÃ¼hrt und uns sowohl mit dem klassischen Collaborative Filtering (User- & Itembased) sowie Content-Based Filtering beschÃ¤ftigt. AnschlieÃŸend wurden beide Methoden kombiniert in einem Hybriden Recommender. Dieser Ansatz verbesserte den MAE minimal weshalb wir uns noch mit einem Deep-Learning Recommender beschÃ¤ftigten.\n",
    "\n",
    "---\n",
    "\n",
    "Der Deep-Learning Recommender performte besser, jedoch aufgrund der geringen Datenmenge nach wie vor nicht perfekt. ZusÃ¤tzlich zum besten MAE liefert der Deep-Learning Recommender den Vorteil, nach einmaligem Training schnell Empfehlungen liefern zu kÃ¶nnen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4593c5f25d4441af",
   "metadata": {},
   "source": [
    "Um diesen Recommender zu testen stellen wir eine struktur bereit wobei lediglich der parameter `testdata` angepasst werden muss um den evaluationsdatensatz zu verwenden. Aufrgund der sehr nah beieinanderliegenden Ergebnisse fÃ¼r pearson und cosine stellen wir beide Testprofile zur VerfÃ¼gung."
   ]
  },
  {
   "cell_type": "code",
   "id": "3b9bbc3845fde0ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:41.298406Z",
     "start_time": "2025-06-16T13:08:41.294303Z"
    }
   },
   "source": [
    "choosen_recommender_profile = [\n",
    "    Test(name=\"ChoosenDeepLearning\", type=\"deep_learning\")\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "758ad31df10683b8"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### Optionale (andere) Testprofile die verwendet wurden und vollstÃ¤ndigkeitshalber hier aufgefÃ¼hrt sind",
   "id": "649e17ae98cdff8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:41.333829Z",
     "start_time": "2025-06-16T13:08:41.326376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "collaborative_filtering_profiles = [\n",
    "    Test(name=\"UserBased_1_cosine\", type=\"collaborative_filtering\", mode=\"user\", k_value=4, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"UserBased_2_cosine\", type=\"collaborative_filtering\", mode=\"user\", k_value=3, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"UserBased_3_cosine\", type=\"collaborative_filtering\", mode=\"user\", k_value=4, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"UserBased_4_cosine\", type=\"collaborative_filtering\", mode=\"user\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "\n",
    "    Test(name=\"ItemBased_1_cosine\", type=\"collaborative_filtering\", mode=\"item\", k_value=4, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"ItemBased_2_cosine\", type=\"collaborative_filtering\", mode=\"item\", k_value=3, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"ItemBased_3_cosine\", type=\"collaborative_filtering\", mode=\"item\", k_value=4, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"ItemBased_4_cosine\", type=\"collaborative_filtering\", mode=\"item\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
    "\n",
    "    Test(name=\"UserBased_1_pearson\", type=\"collaborative_filtering\", mode=\"user\", k_value=4, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"UserBased_2_pearson\", type=\"collaborative_filtering\", mode=\"user\", k_value=3, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"UserBased_3_pearson\", type=\"collaborative_filtering\", mode=\"user\", k_value=4, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"UserBased_4_pearson\", type=\"collaborative_filtering\", mode=\"user\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "\n",
    "    Test(name=\"ItemBased_1_pearson\", type=\"collaborative_filtering\", mode=\"item\", k_value=4, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"ItemBased_2_pearson\", type=\"collaborative_filtering\", mode=\"item\", k_value=3, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"ItemBased_3_pearson\", type=\"collaborative_filtering\", mode=\"item\", k_value=4, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "    Test(name=\"ItemBased_4_pearson\", type=\"collaborative_filtering\", mode=\"item\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
    "]"
   ],
   "id": "588826d545fb7fef",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:41.352636Z",
     "start_time": "2025-06-16T13:08:41.347580Z"
    }
   },
   "cell_type": "code",
   "source": [
    "content_based_profiles = [\n",
    "    Test(name=\"ContentBased_1\", type=\"content_based\", k_value=3),\n",
    "    Test(name=\"ContentBased_2\", type=\"content_based\", k_value=4),\n",
    "    Test(name=\"ContentBased_3\", type=\"content_based\", k_value=5),\n",
    "    Test(name=\"ContentBased_4\", type=\"content_based\", k_value=6),\n",
    "    Test(name=\"ContentBased_5\", type=\"content_based\", k_value=7),\n",
    "    Test(name=\"ContentBased_6\", type=\"content_based\", k_value=8),\n",
    "    Test(name=\"ContentBased_7\", type=\"content_based\", k_value=9),\n",
    "    Test(name=\"ContentBased_8\", type=\"content_based\", k_value=10),\n",
    "    Test(name=\"ContentBased_9\", type=\"content_based\", k_value=11),\n",
    "    Test(name=\"ContentBased_10\", type=\"content_based\", k_value=12),\n",
    "    Test(name=\"ContentBased_11\", type=\"content_based\", k_value=13),\n",
    "    Test(name=\"ContentBased_12\", type=\"content_based\", k_value=14),\n",
    "]"
   ],
   "id": "d1df2dc28368aa35",
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "45018afb4c4d0655",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:41.384564Z",
     "start_time": "2025-06-16T13:08:41.380088Z"
    }
   },
   "source": [
    "deep_learning_profiles = [\n",
    "    # Test(name=\"deep_learning_large_embedding\", type=\"deep_learning\", embedding_dim=128, epochs=25, batch_size=128),\n",
    "    # Test(name=\"deep_learning_small_batch\", type=\"deep_learning\", embedding_dim=64, epochs=25, batch_size=64),\n",
    "    # Test(name=\"deep_learning_large_batch\", type=\"deep_learning\", embedding_dim=64, epochs=25, batch_size=256),\n",
    "    # Test(name=\"deep_learning_more_epochs\", type=\"deep_learning\", embedding_dim=64, epochs=50, batch_size=128),\n",
    "    # Test(name=\"deep_learning_less_epochs\", type=\"deep_learning\", embedding_dim=64, epochs=10, batch_size=128),\n",
    "    # Test(name=\"deep_learning_less_epochs\", type=\"deep_learning\", embedding_dim=64, epochs=10, batch_size=128),\n",
    "    # Test(name=\"deep_learning_finetuning_1\", type=\"deep_learning\", embedding_dim=48, epochs=10, batch_size=128),\n",
    "    # Test(name=\"deep_learning_finetuning_2\", type=\"deep_learning\", embedding_dim=16, epochs=25, batch_size=128),\n",
    "    Test(name=\"deep_learning_finetuning_3\", type=\"deep_learning\", embedding_dim=16, epochs=25, batch_size=64),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:41.426422Z",
     "start_time": "2025-06-16T13:08:41.419073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "hybrid_profiles = [\n",
    "    Test(name=\"Hybrid_1\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.5),\n",
    "    Test(name=\"Hybrid_2\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.75),\n",
    "    Test(name=\"Hybrid_3\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.25),\n",
    "\n",
    "    Test(name=\"Hybrid_4\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.5),\n",
    "    Test(name=\"Hybrid_5\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.75),\n",
    "    Test(name=\"Hybrid_6\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.25),\n",
    "\n",
    "    Test(name=\"Hybrid_7\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.5),\n",
    "    Test(name=\"Hybrid_8\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.75),\n",
    "    Test(name=\"Hybrid_9\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.25),\n",
    "\n",
    "    Test(name=\"Hybrid_10\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.5),\n",
    "    Test(name=\"Hybrid_11\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.75),\n",
    "    Test(name=\"Hybrid_12\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.25),\n",
    "\n",
    "]"
   ],
   "id": "90d35683f5188ea9",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "c3de1e9f7ef06c96"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Aufruf des MAE Testers\n",
    "Dem Tester werden die entscheidenden Daten Ã¼bergeben und anschlieÃŸend wird der MAE fÃ¼r die ausgewÃ¤hlten / Ã¼bergebenene Test-Profile ermittelt"
   ],
   "id": "dab2f1ae84c66fb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:41.458254Z",
     "start_time": "2025-06-16T13:08:41.454490Z"
    }
   },
   "cell_type": "code",
   "source": "testdata_path = \"./data/Testdaten_FlixNet.csv\"   # change to use another Test/Eval-Dataset",
   "id": "ff1a9deee9507f5b",
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "1a177fda3e3854fd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:41.552693Z",
     "start_time": "2025-06-16T13:08:41.495641Z"
    }
   },
   "source": [
    "tester = MAETester(\n",
    "        tests=deep_learning_profiles,\n",
    "        test_data_path=testdata_path,\n",
    "        data_path=\"./data/Bewertungsmatrix_FlixNet.csv\",\n",
    "        ratings=\"./data/Ratings_FlixNet.csv\",\n",
    "        item_profile_path=\"./data/Itemprofile_FlixNet.csv\",\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "1259e7059201639c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-16T13:08:57.484989Z",
     "start_time": "2025-06-16T13:08:41.564792Z"
    }
   },
   "source": [
    "result = tester.run_tests()\n",
    "result # print result here as dataframe"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[32m2025-06-16 15:08:41.565\u001B[0m | \u001B[1mINFO    \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m_run_test\u001B[0m:\u001B[36m67\u001B[0m - \u001B[1mRunning test: deep_learning_finetuning_3\u001B[0m\n",
      "Vorhersagen werden berechnet:   0%|          | 0/1595 [00:00<?, ?it/s]\u001B[32m2025-06-16 15:08:44.065\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 1\t| Training Loss: 2.0041597374491817 \t| Validation MAE: 1.7256475801378208\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:44.544\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 2\t| Training Loss: 0.6869050349912716 \t| Validation MAE: 0.858873387638678\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:45.060\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 3\t| Training Loss: 0.4095431114104311 \t| Validation MAE: 0.7903280156533172\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:45.546\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 4\t| Training Loss: 0.35750216540274965 \t| Validation MAE: 0.754687815699084\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:46.027\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 5\t| Training Loss: 0.3267716343865195 \t| Validation MAE: 0.7426268000587775\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:46.529\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 6\t| Training Loss: 0.2991387599887957 \t| Validation MAE: 0.7247153374842342\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:47.019\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 7\t| Training Loss: 0.27924929474243193 \t| Validation MAE: 0.7070430456657768\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:47.509\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 8\t| Training Loss: 0.2616852129820182 \t| Validation MAE: 0.6986822265816333\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:48.007\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 9\t| Training Loss: 0.2473446995926447 \t| Validation MAE: 0.691115003245004\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:48.497\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 10\t| Training Loss: 0.2373168807859203 \t| Validation MAE: 0.6862625887401426\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:49.001\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 11\t| Training Loss: 0.22724579688260763 \t| Validation MAE: 0.6800658438272984\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:49.515\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 12\t| Training Loss: 0.21905818788384304 \t| Validation MAE: 0.6772902031303574\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:50.007\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 13\t| Training Loss: 0.21264096120011217 \t| Validation MAE: 0.675891323747306\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:50.496\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 14\t| Training Loss: 0.20604111078574178 \t| Validation MAE: 0.674119029747655\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:50.990\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 15\t| Training Loss: 0.20239751783160656 \t| Validation MAE: 0.674554197018423\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:51.474\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 16\t| Training Loss: 0.19715461129244743 \t| Validation MAE: 0.6737697134944712\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:51.964\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 17\t| Training Loss: 0.19400228780938644 \t| Validation MAE: 0.6722673685199415\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:52.462\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 18\t| Training Loss: 0.1925584696828186 \t| Validation MAE: 0.6730401616111444\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:52.947\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 19\t| Training Loss: 0.18864922871381157 \t| Validation MAE: 0.6751597915697247\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:53.460\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 20\t| Training Loss: 0.1867046960888027 \t| Validation MAE: 0.6754257823979967\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:53.964\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 21\t| Training Loss: 0.18521765018937253 \t| Validation MAE: 0.6766141359335203\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:54.530\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 22\t| Training Loss: 0.1698803212989419 \t| Validation MAE: 0.6773359101394127\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:55.039\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 23\t| Training Loss: 0.16793531729014655 \t| Validation MAE: 0.6753274780082105\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:55.570\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 24\t| Training Loss: 0.16649935510675262 \t| Validation MAE: 0.6759558387684598\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:56.064\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 25\t| Training Loss: 0.16514959169318014 \t| Validation MAE: 0.6767491331668483\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:56.545\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 26\t| Training Loss: 0.15687861038591472 \t| Validation MAE: 0.6765999055581406\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:57.143\u001B[0m | \u001B[34m\u001B[1mDEBUG   \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mfit\u001B[0m:\u001B[36m156\u001B[0m - \u001B[34m\u001B[1mEpoche 27\t| Training Loss: 0.15551958071641594 \t| Validation MAE: 0.6757243811149956\u001B[0m\n",
      "Vorhersagen werden berechnet: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1595/1595 [00:15<00:00, 100.33it/s]\n",
      "\u001B[32m2025-06-16 15:08:57.467\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36mrun_tests\u001B[0m:\u001B[36m56\u001B[0m - \u001B[32m\u001B[1mTest abgeschlossen: deep_learning_finetuning_3, MAE: 0.6652\n",
      "\u001B[0m\n",
      "\u001B[32m2025-06-16 15:08:57.472\u001B[0m | \u001B[32m\u001B[1mSUCCESS \u001B[0m | \u001B[36m__main__\u001B[0m:\u001B[36m_save_to_file\u001B[0m:\u001B[36m188\u001B[0m - \u001B[32m\u001B[1mTestergebnisse erfolgreich gespeichert.\u001B[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Zusammenfassung der Testergebnisse:\n",
      "                  Testname Recomendertyp Modus k-Wert Metrik Berechnungsvariante Alpha (weight)      MAE\n",
      "deep_learning_finetuning_3 deep_learning     /      /      /                   /              / 0.665204\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                     Testname  Recomendertyp Modus k-Wert Metrik  \\\n",
       "0  deep_learning_finetuning_3  deep_learning     /      /      /   \n",
       "\n",
       "  Berechnungsvariante Alpha (weight)       MAE  \n",
       "0                   /              /  0.665204  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Testname</th>\n",
       "      <th>Recomendertyp</th>\n",
       "      <th>Modus</th>\n",
       "      <th>k-Wert</th>\n",
       "      <th>Metrik</th>\n",
       "      <th>Berechnungsvariante</th>\n",
       "      <th>Alpha (weight)</th>\n",
       "      <th>MAE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>deep_learning_finetuning_3</td>\n",
       "      <td>deep_learning</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>0.665204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "---",
   "id": "1a2cca56ff8816bf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Ergebnis aller Testcases (ohne DeepLearning)",
   "id": "d89bfb0a22521540"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Testname              | Recomendertyp           | Modus                  | k-Wert | Metrik  | Berechnungsvariante | Alpha (weight) | MAE      |\n",
    "|-----------------------|--------------------------|-------------------------|--------|---------|----------------------|----------------|----------|\n",
    "| UserBased_1_cosine    | collaborative_filtering | user                   | 2      | cosine  | weighted             | /              | 0.870846 |\n",
    "| UserBased_2_cosine    | collaborative_filtering | user                   | 3      | cosine  | weighted             | /              | 0.815674 |\n",
    "| UserBased_3_cosine    | collaborative_filtering | user                   | 4      | cosine  | weighted             | /              | 0.785266 |\n",
    "| UserBased_4_cosine    | collaborative_filtering | user                   | 5      | cosine  | weighted             | /              | 0.774922 |\n",
    "| ItemBased_1_cosine    | collaborative_filtering | item                   | 2      | cosine  | weighted             | /              | 0.933542 |\n",
    "| ItemBased_2_cosine    | collaborative_filtering | item                   | 3      | cosine  | weighted             | /              | 0.884013 |\n",
    "| ItemBased_3_cosine    | collaborative_filtering | item                   | 4      | cosine  | weighted             | /              | 0.855799 |\n",
    "| ItemBased_4_cosine    | collaborative_filtering | item                   | 5      | cosine  | weighted             | /              | 0.841066 |\n",
    "| UserBased_1_pearson   | collaborative_filtering | user                   | 2      | pearson | weighted             | /              | 0.865831 |\n",
    "| UserBased_2_pearson   | collaborative_filtering | user                   | 3      | pearson | weighted             | /              | 0.805956 |\n",
    "| UserBased_3_pearson   | collaborative_filtering | user                   | 4      | pearson | weighted             | /              | 0.781505 |\n",
    "| UserBased_4_pearson   | collaborative_filtering | user                   | 5      | pearson | weighted             | /              | 0.771473 |\n",
    "| ItemBased_1_pearson   | collaborative_filtering | item                   | 2      | pearson | weighted             | /              | 0.927273 |\n",
    "| ItemBased_2_pearson   | collaborative_filtering | item                   | 3      | pearson | weighted             | /              | 0.873981 |\n",
    "| ItemBased_3_pearson   | collaborative_filtering | item                   | 4      | pearson | weighted             | /              | 0.847022 |\n",
    "| ItemBased_4_pearson   | collaborative_filtering | item                   | 5      | pearson | weighted             | /              | 0.825078 |\n",
    "| ContentBased_1        | content_based           | /                      | 3      | /       | /                    | /              | 0.878683 |\n",
    "| ContentBased_2        | content_based           | /                      | 4      | /       | /                    | /              | 0.839812 |\n",
    "| ContentBased_3        | content_based           | /                      | 5      | /       | /                    | /              | 0.822571 |\n",
    "| ContentBased_4        | content_based           | /                      | 6      | /       | /                    | /              | 0.830721 |\n",
    "| ContentBased_5        | content_based           | /                      | 7      | /       | /                    | /              | 0.827273 |\n",
    "| ContentBased_6        | content_based           | /                      | 8      | /       | /                    | /              | 0.816928 |\n",
    "| ContentBased_7        | content_based           | /                      | 9      | /       | /                    | /              | 0.813166 |\n",
    "| ContentBased_8        | content_based           | /                      | 10     | /       | /                    | /              | 0.813793 |\n",
    "| ContentBased_9        | content_based           | /                      | 11     | /       | /                    | /              | 0.815047 |\n",
    "| ContentBased_10       | content_based           | /                      | 12     | /       | /                    | /              | 0.800313 |\n",
    "| ContentBased_11       | content_based           | /                      | 13     | /       | /                    | /              | 0.803448 |\n",
    "| ContentBased_12       | content_based           | /                      | 14     | /       | /                    | /              | 0.802821 |\n",
    "| Hybrid_1              | hybrid                  | /                      | 5      | /       | /                    | 0.5            | 0.739812 |\n",
    "| Hybrid_2              | hybrid                  | /                      | 5      | /       | /                    | 0.75           | 0.743887 |\n",
    "| Hybrid_3              | hybrid                  | /                      | 5      | /       | /                    | 0.25           | 0.786834 |\n",
    "| Hybrid_4              | hybrid                  | /                      | 5      | /       | /                    | 0.5            | 0.720376 |\n",
    "| Hybrid_5              | hybrid                  | /                      | 5      | /       | /                    | 0.75           | 0.737304 |\n",
    "| Hybrid_6              | hybrid                  | /                      | 5      | /       | /                    | 0.25           | 0.741379 |\n",
    "| Hybrid_7              | hybrid                  | /                      | 5      | /       | /                    | 0.5            | 0.741379 |\n",
    "| Hybrid_8              | hybrid                  | /                      | 5      | /       | /                    | 0.75           | 0.742006 |\n",
    "| Hybrid_9              | hybrid                  | /                      | 5      | /       | /                    | 0.25           | 0.787147 |\n",
    "| Hybrid_10             | hybrid                  | /                      | 5      | /       | /                    | 0.5            | 0.720376 |\n",
    "| Hybrid_11             | hybrid                  | /                      | 5      | /       | /                    | 0.75           | 0.735110 |\n",
    "| Hybrid_12             | hybrid                  | /                      | 5      | /       | /                    | 0.25           | 0.740125 |\n"
   ],
   "id": "aed60a2229874d9a"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
