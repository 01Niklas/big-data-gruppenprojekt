{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "5ffb10be",
      "metadata": {
        "id": "5ffb10be"
      },
      "source": [
        "# Gruppenprojekt - Big Data Analysis\n",
        "Dieses Notebook beschreibt unser Programm und bietet einen Ãœberblik Ã¼ber unser Projekt mit den *FlixNet*â€‘Daten.\n",
        "\n",
        "**INFO**: Dieses Projekt wurde in einem [Github Repository](https://github.com/01Niklas/big-data-gruppenprojekt) entwickelt und wurde im nachgang in dieses Notebook Ã¼bertragen.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bce9b3c",
      "metadata": {
        "id": "9bce9b3c"
      },
      "source": [
        "## ðŸ”§ Libraries & Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install loguru # install our logging library\n",
        "%pip install optuna # install the library we used to optimize hyperparameters for deep learning recommender"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmtF7QM9AbrY",
        "outputId": "8de194e9-b6ad-4c63-f005-36172c325150"
      },
      "id": "JmtF7QM9AbrY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: loguru in /usr/local/lib/python3.11/dist-packages (0.7.3)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.4.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "id": "e6fd62392feb88db",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:03.971132Z",
          "start_time": "2025-06-13T15:46:03.966205Z"
        },
        "id": "e6fd62392feb88db"
      },
      "source": [
        "from abc import abstractmethod\n",
        "from datetime import datetime\n",
        "from typing import List\n",
        "from typing import Optional, Literal, Dict, Any\n",
        "\n",
        "import numpy as np\n",
        "import optuna\n",
        "import pandas as pd\n",
        "import scipy.stats as stats\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from loguru import logger\n",
        "from pydantic import BaseModel\n",
        "from scipy.sparse import csr_matrix\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "1adeaf18e76f57ae"
      },
      "cell_type": "markdown",
      "source": [
        "## Recommender deklarieren\n",
        "(Base-Recommender, Collaborative Filtering, Content-Based und Deep-Learning-Recommender)"
      ],
      "id": "1adeaf18e76f57ae"
    },
    {
      "cell_type": "code",
      "id": "813ebe70194fc0a4",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:03.991154Z",
          "start_time": "2025-06-13T15:46:03.985381Z"
        },
        "id": "813ebe70194fc0a4"
      },
      "source": [
        "class Recommender:\n",
        "    def __init__(self):\n",
        "        self.k = 3 # default\n",
        "        self.user_id = None\n",
        "        self.item_id = None\n",
        "        self.similarity: Literal[\"cosine\", \"pearson\"] = \"cosine\"  # default\n",
        "        self.calculation_variant: Literal[\"weighted\", \"unweighted\"] = \"weighted\"  # default\n",
        "        self.data = None\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def _preprocess_data(self):\n",
        "        ...\n",
        "\n",
        "\n",
        "    def _prepare_information(self, user_id: str, item_id: str, k: int, similarity: Literal[\"cosine\", \"pearson\"] = \"cosine\", calculation_variant: Literal[\"weighted\", \"unweighted\"] = \"weighted\") -> None:\n",
        "        self.user_id = user_id\n",
        "        self.item_id = item_id\n",
        "        self.similarity = similarity\n",
        "        self.calculation_variant = calculation_variant\n",
        "        self.k = k\n",
        "\n",
        "        if similarity == 'pearson' and self.data is not None:\n",
        "            self.data['mean'] = self.data.mean(axis=1)\n",
        "\n",
        "\n",
        "    @abstractmethod\n",
        "    def predict(\n",
        "            self,\n",
        "            user_id: str,\n",
        "            item_id: str,\n",
        "            similarity: Optional[Literal['cosine', 'pearson']] = 'cosine',   # only for collaborative filtering\n",
        "            calculation_variety: Optional[Literal['weighted', 'unweighted']] = 'weighted',  # only for collaborative filtering\n",
        "            k: Optional[int] = 3,\n",
        "            second_k_value: Optional[int] = None):\n",
        "        ..."
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "cad50448f6df9a05",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:04.023169Z",
          "start_time": "2025-06-13T15:46:04.006764Z"
        },
        "id": "cad50448f6df9a05"
      },
      "source": [
        "class CollaborativeFilteringRecommender(Recommender):\n",
        "    def __init__(self, data: pd.DataFrame, mode: Literal['user', 'item'] = 'user', display_results_for_each_step: Optional[bool] = False) -> None:\n",
        "        super().__init__()\n",
        "        self.display_results_for_each_step = display_results_for_each_step\n",
        "        self.original_data = data\n",
        "        self.mode = mode\n",
        "        self._preprocess_data()\n",
        "\n",
        "\n",
        "    def _preprocess_data(self) -> None:\n",
        "        self.original_data = self.original_data.set_index(\"user_ID\")\n",
        "        self.original_data.index = self.original_data.index.astype(str) # convert the index to string (due to error with int values)\n",
        "        if self.mode == 'item':\n",
        "            self.data = self.original_data.T  # transpose for item based\n",
        "        else:\n",
        "            self.data = self.original_data  # original for user based\n",
        "\n",
        "\n",
        "    def _calculate_distance_and_indices(self, dataframe: pd.DataFrame) -> ([], []):\n",
        "        knn = NearestNeighbors(metric=\"cosine\", algorithm='brute')\n",
        "        knn.fit(dataframe.values)\n",
        "        distances, indices = knn.kneighbors(dataframe.values, n_neighbors=self.k + 1)\n",
        "\n",
        "        if self.mode == 'item':\n",
        "            index = dataframe.index.get_loc(self.item_id)\n",
        "        else:\n",
        "            index = dataframe.index.get_loc(self.user_id)\n",
        "\n",
        "        similar_distances = distances[index, 1:]\n",
        "        similar_indices = indices[index, 1:]\n",
        "\n",
        "        return similar_distances, similar_indices\n",
        "\n",
        "    def _calculate_similarities(self, similar_distances: np.ndarray) -> np.ndarray:\n",
        "        similarity = [1 - x for x in similar_distances]\n",
        "        similarity = [(y + 1) / 2 for y in similarity]\n",
        "        return np.array(similarity)\n",
        "\n",
        "    def _calculate_result(self, similarity: np.ndarray, ratings: np.ndarray) -> float:\n",
        "        if self.calculation_variant == \"weighted\":\n",
        "            mean = np.dot(ratings, similarity) / similarity.sum()\n",
        "            return mean\n",
        "        else:\n",
        "            return float(np.mean(ratings))\n",
        "\n",
        "    def _check_values(self) -> None:\n",
        "        if self.mode == 'user':\n",
        "            if self.user_id not in self.data.index:\n",
        "                raise ValueError(f\"User {self.user_id} nicht in Daten.\")\n",
        "            if self.item_id not in self.data.columns:\n",
        "                raise ValueError(f\"Item {self.item_id} nicht in Daten.\")\n",
        "        elif self.mode == 'item':\n",
        "            if self.user_id not in self.original_data.index:\n",
        "                raise ValueError(\n",
        "                    f\"User {self.user_id} nicht in Originaldaten.\")\n",
        "            if self.item_id not in self.data.index:\n",
        "                raise ValueError(\n",
        "                    f\"Item {self.item_id} nicht in transponierten Daten.\")\n",
        "\n",
        "    def _process_item_based(self) -> pd.DataFrame:\n",
        "        user_ratings = self.original_data.loc[self.user_id]\n",
        "\n",
        "        # filter based on the item. Only the users that already gave a rating are relevant\n",
        "        rated_items = user_ratings[user_ratings > 0.0].index.tolist()\n",
        "\n",
        "        if not rated_items:\n",
        "            raise ValueError(f\"User {self.user_id} hat keine Items bewertet!\")\n",
        "\n",
        "        return self.data.loc[rated_items + [self.item_id]]\n",
        "\n",
        "    def _process_user_based(self) -> pd.DataFrame:\n",
        "        # filter based on the item. Only the users that already gave a rating are relevant\n",
        "        relevant_df = self.data[self.data[self.item_id] > 0.0]\n",
        "\n",
        "        # add the user we are looking for (due to non-existing rating this user where filtered out)\n",
        "        return pd.concat([relevant_df, self.data.loc[[self.user_id]]])\n",
        "\n",
        "    def _normalize_for_pearson(self, relevant_df: pd.DataFrame) -> pd.DataFrame:\n",
        "        mean_values = relevant_df.mean(axis=1).to_numpy()\n",
        "        relevant_df = relevant_df.sub(mean_values, axis=0)\n",
        "        return relevant_df\n",
        "\n",
        "    def predict(\n",
        "            self,\n",
        "            user_id: str,\n",
        "            item_id: str,\n",
        "            similarity: Literal['cosine', 'pearson'] = 'cosine',\n",
        "            calculation_variety: Literal['weighted', 'unweighted'] = 'weighted',\n",
        "            k: Optional[int] = 3,\n",
        "            second_k_value: Optional[int] = None) -> float:\n",
        "        self._prepare_information(user_id=user_id, item_id=item_id, similarity=similarity, calculation_variant=calculation_variety, k=k)\n",
        "        self._check_values()\n",
        "\n",
        "        if self.mode == 'item':\n",
        "            relevant_df = self._process_item_based()\n",
        "        else:\n",
        "            relevant_df = self._process_user_based()\n",
        "\n",
        "        if similarity == 'pearson':\n",
        "            self._normalize_for_pearson(relevant_df)\n",
        "\n",
        "        # make sure that there are no NaN values -> set NaN to 0.0\n",
        "        relevant_df = relevant_df.fillna(0.0)\n",
        "        similar_distances, similar_indices = self._calculate_distance_and_indices(dataframe=relevant_df)\n",
        "\n",
        "        if self.mode == 'item':\n",
        "            ratings = relevant_df.iloc[similar_indices][self.user_id].to_numpy()\n",
        "        else:\n",
        "            ratings = relevant_df.iloc[similar_indices][self.item_id].to_numpy()\n",
        "\n",
        "        similarity = self._calculate_similarities(similar_distances)\n",
        "        result = self._calculate_result(similarity, ratings)\n",
        "\n",
        "        if self.display_results_for_each_step:\n",
        "          self.explain(similar_indices, relevant_df, ratings, similarity, result)\n",
        "\n",
        "        return result\n",
        "\n",
        "    def explain(self, similar_indices, relevant_df, ratings, similarity, result) -> None:\n",
        "        print(\"-\" * 50)\n",
        "        print(f\"<mode: {self.mode}>\")\n",
        "        print(f\"({self.calculation_variant}) Mittelwert: {result:.4f}\")\n",
        "        print(f\"Metrik: {self.similarity}\")\n",
        "        print()\n",
        "        print(f\"k ({self.k}) Ã¤hnlichsten {'Items' if self.mode == 'item' else 'Nutzer'}:\")\n",
        "        df = pd.DataFrame({\n",
        "            \"ID\": relevant_df.index[similar_indices],\n",
        "            \"rating\": ratings,\n",
        "            \"similarity\": similarity\n",
        "        }).reset_index(drop=True)\n",
        "        print(df.to_string(index=True, header=True))\n",
        "        print(\"-\" * 50)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "6928825fe8030222",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:04.057007Z",
          "start_time": "2025-06-13T15:46:04.038293Z"
        },
        "id": "6928825fe8030222"
      },
      "source": [
        "class ContentBasedRecommender(Recommender):\n",
        "    def __init__(self, item_profile: pd.DataFrame, user_ratings: pd.DataFrame) -> None:\n",
        "        super().__init__()\n",
        "        self.item_profile = item_profile\n",
        "        self.user_ratings = user_ratings\n",
        "        self.k = 3\n",
        "        self.feature_matrix = None\n",
        "        self._preprocess_data()\n",
        "\n",
        "        # check if the features \"budget\", \"revenue\", \"runtime\" are relevant for the item/rating correlation\n",
        "        self._check_features_correlation(features=[\"budget\", \"revenue\", \"runtime\"])\n",
        "        self._calculate_tfidf_matrix()\n",
        "\n",
        "\n",
        "    def _preprocess_data(self):\n",
        "        self.item_profile[\"item_ID\"] = self.item_profile[\"item_ID\"].astype(str)\n",
        "        self.user_ratings[\"item_ID\"] = self.user_ratings[\"item_ID\"].astype(str)\n",
        "        self.user_ratings[\"user_ID\"] = self.user_ratings[\"user_ID\"].astype(str)\n",
        "\n",
        "    def _check_features_correlation(self, features: List[str]) -> None:\n",
        "        irrelevant_features = []  #  list for irrelevant feature that will be removed\n",
        "\n",
        "        for feature in features:\n",
        "            if feature not in self.item_profile.columns:\n",
        "                continue\n",
        "\n",
        "            # combine item and user ratings\n",
        "            merged_data = pd.merge(self.user_ratings, self.item_profile, on=\"item_ID\")\n",
        "\n",
        "            # convert to numeric\n",
        "            feature_data = pd.to_numeric(merged_data[feature].fillna(0), errors=\"coerce\")\n",
        "            rating_data = pd.to_numeric(merged_data[\"rating\"].fillna(0), errors=\"coerce\")\n",
        "\n",
        "            # calculate the correlation between the user rating and the feature\n",
        "            correlation, p_value = stats.pearsonr(feature_data, rating_data)\n",
        "\n",
        "            # check if the correlation is relevant / significant\n",
        "            if abs(correlation) < 0.1 or p_value > 0.05:\n",
        "                logger.debug(f\"Feature '{feature}' does not have a sigificant correlation and will be ignored.\")\n",
        "                irrelevant_features.append(feature)\n",
        "            else:\n",
        "                logger.debug(f\"Feature '{feature}' has a significant correlation: {correlation}\")\n",
        "\n",
        "        self.item_profile.drop(columns=irrelevant_features, inplace=True)\n",
        "\n",
        "\n",
        "    def _safe_get_feature(self, feature_name):\n",
        "        if feature_name in self.item_profile.columns:\n",
        "            return self.item_profile[feature_name]\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def _calculate_tfidf_matrix(self) -> None:\n",
        "        # optional but if the title is empty we set it as an empty string\n",
        "        self.item_profile[\"title\"] = self.item_profile[\"title\"].fillna(\"\")\n",
        "\n",
        "        # use the TfidfVectorizer() to transform title into numerical feature\n",
        "        title_vectorizer = TfidfVectorizer()\n",
        "        title_features = title_vectorizer.fit_transform(self.item_profile[\"title\"])\n",
        "\n",
        "        # change genre columns in text by just extracting the word after '\"Genre_\"'\n",
        "        genre_cols = [col for col in self.item_profile.columns if col.startswith(\"Genre_\")]\n",
        "        if genre_cols:\n",
        "            self.item_profile[\"genre_text\"] = self.item_profile[genre_cols].astype(int).apply(\n",
        "                lambda row: \" \".join([col.replace(\"Genre_\", \"\") for col, val in row.items() if val == 1]), axis=1\n",
        "            )\n",
        "            genre_vectorizer = TfidfVectorizer()\n",
        "            genre_features = genre_vectorizer.fit_transform(self.item_profile[\"genre_text\"])\n",
        "        else:\n",
        "            genre_features = np.empty((len(self.item_profile), 0))\n",
        "\n",
        "        # the language of the items transformed into one-hot-encoded-dummies\n",
        "        language_dummies = pd.get_dummies(self.item_profile[\"original_language\"], prefix=\"lang\")\n",
        "\n",
        "        # put runtime into three categories (short, medium, long)\n",
        "        runtime_feature = self._safe_get_feature(\"runtime\")\n",
        "        if runtime_feature is not None:\n",
        "            runtime_bucket = pd.qcut(runtime_feature, q=3, labels=[\"kurz\", \"mittel\", \"lang\"])\n",
        "            runtime_dummies = pd.get_dummies(runtime_bucket, prefix=\"runtime\")\n",
        "        else:\n",
        "            runtime_dummies = pd.DataFrame(index=self.item_profile.index)\n",
        "\n",
        "        # budget and include will be logarithmically transformed and then scaled\n",
        "        numerical_features = []\n",
        "        if \"budget\" in self.item_profile.columns:\n",
        "            self.item_profile[\"log_budget\"] = np.log1p(self.item_profile[\"budget\"].fillna(0))\n",
        "            numerical_features.append(\"log_budget\")\n",
        "        if \"revenue\" in self.item_profile.columns:\n",
        "            self.item_profile[\"log_revenue\"] = np.log1p(self.item_profile[\"revenue\"].fillna(0))\n",
        "            numerical_features.append(\"log_revenue\")\n",
        "\n",
        "        if numerical_features:\n",
        "            scaler = StandardScaler()\n",
        "            scaled_numericals = scaler.fit_transform(self.item_profile[numerical_features])\n",
        "        else:\n",
        "            scaled_numericals = np.empty((len(self.item_profile), 0))\n",
        "\n",
        "        # create feature matrix\n",
        "        self.feature_matrix = hstack([\n",
        "            title_features,\n",
        "            genre_features,\n",
        "            language_dummies.values,\n",
        "            runtime_dummies.values,\n",
        "            scaled_numericals\n",
        "        ])\n",
        "\n",
        "        self.feature_matrix = csr_matrix(self.feature_matrix)\n",
        "\n",
        "    def _check_values(self):\n",
        "        if self.user_id not in self.user_ratings[\"user_ID\"].values:\n",
        "            raise ValueError(f\"User-ID {self.user_id} not found.\")\n",
        "\n",
        "        if self.item_id not in self.item_profile[\"item_ID\"].values:\n",
        "            raise ValueError(f\"Item-ID {self.item_id} not found.\")\n",
        "\n",
        "\n",
        "    def predict(\n",
        "            self,\n",
        "            user_id: str,\n",
        "            item_id: str,\n",
        "            similarity: Optional[Literal['cosine', 'pearson']] = 'cosine',  # only for collaborative filtering\n",
        "            calculation_variety: Optional[Literal['weighted', 'unweighted']] = 'weighted', # only for collaborative filtering\n",
        "            k: Optional[int] = 3,\n",
        "            second_k_value: Optional[int] = None) -> float:\n",
        "\n",
        "        # default function to save all the information\n",
        "        self._prepare_information(user_id=user_id, item_id=item_id, k=k)\n",
        "\n",
        "        # check if the values included in the dataframes\n",
        "        self._check_values()\n",
        "\n",
        "        # extract only the items, the user rated\n",
        "        rated_items = self.user_ratings[self.user_ratings[\"user_ID\"] == user_id]\n",
        "        rated_item_ids = rated_items[\"item_ID\"].values\n",
        "\n",
        "        # this case can happen when k is greater than the rated items by the user\n",
        "        if self.k > len(rated_item_ids):\n",
        "            self.k = len(rated_item_ids)\n",
        "\n",
        "        # extract the rated item indices from the item profile\n",
        "        rated_item_indices = self.item_profile[self.item_profile[\"item_ID\"].isin(rated_item_ids)].index\n",
        "\n",
        "        # check if the user rated some items... if not then return 0.0\n",
        "        if len(rated_item_indices) == 0:\n",
        "            return 0.0\n",
        "\n",
        "        # get the feature matrix that is calculated in the '_calculate_tfidf_matrix()'-Method\n",
        "        filtered_matrix = self.feature_matrix[rated_item_indices]\n",
        "\n",
        "        # default kNN usage like in the lecture with brute algorithm and cosine as metric\n",
        "        knn = NearestNeighbors(metric=\"cosine\", algorithm=\"brute\")\n",
        "        knn.fit(filtered_matrix)\n",
        "\n",
        "        item_index = self.item_profile[self.item_profile[\"item_ID\"] == item_id].index[0]\n",
        "        distances, indices = knn.kneighbors(self.feature_matrix[item_index], n_neighbors=self.k + 1)  # k+1 because the item itself is also included\n",
        "\n",
        "        # the similar item indices beginning with the first real neighbor\n",
        "        similar_items = indices.flatten()[1:]\n",
        "        similar_item_indices = rated_item_indices[similar_items]\n",
        "\n",
        "        # extract for each item in the similar item indices list the rating and save it in the list\n",
        "        similar_ratings = []\n",
        "        for idx in similar_item_indices:\n",
        "            similar_item_id = self.item_profile.iloc[idx][\"item_ID\"]\n",
        "            user_rating = self.user_ratings[(self.user_ratings[\"user_ID\"] == user_id) & (self.user_ratings[\"item_ID\"] == similar_item_id)]\n",
        "            if not user_rating.empty:\n",
        "                similar_ratings.append(user_rating[\"rating\"].values[0])\n",
        "\n",
        "        # if the similar ratings is zero then we return a default 0.0\n",
        "        if not similar_ratings:\n",
        "            return 0.0\n",
        "\n",
        "        # calculate the predicted rating based on the sum of ratings and len of ratings\n",
        "        return sum(similar_ratings) / len(similar_ratings)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "c8fbff7bb11954ad",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:04.076154Z",
          "start_time": "2025-06-13T15:46:04.070230Z"
        },
        "id": "c8fbff7bb11954ad"
      },
      "source": [
        "class HybridRecommender(Recommender):\n",
        "    def __init__(self, data: pd.DataFrame, item_profile: pd.DataFrame, user_ratings: pd.DataFrame, mode: Literal['user', 'item'] = 'user', alpha: float = 0.5):\n",
        "        super().__init__()\n",
        "        self.collaborative_recommender = CollaborativeFilteringRecommender(data=data, mode=mode)\n",
        "        self.content_based_recommender = ContentBasedRecommender(item_profile=item_profile, user_ratings=user_ratings)\n",
        "        self.alpha = alpha\n",
        "\n",
        "    def predict(\n",
        "            self,\n",
        "            user_id: str,\n",
        "            item_id: str,\n",
        "            similarity: Optional[Literal['cosine', 'pearson']] = 'cosine',  # only for collaborative filtering\n",
        "            calculation_variety: Optional[Literal['weighted', 'unweighted']] = 'weighted', # only for collaborative filtering\n",
        "            k: Optional[int] = 3,\n",
        "            second_k_value: Optional[int] = 3):\n",
        "\n",
        "        collaborative_prediction = self.collaborative_recommender.predict(\n",
        "            user_id=user_id,\n",
        "            item_id=item_id,\n",
        "            similarity=similarity, # ignore that it can be NONE\n",
        "            calculation_variety=calculation_variety, # ignore that it can be NONE\n",
        "            k=k\n",
        "        )\n",
        "\n",
        "        content_based_prediction = self.content_based_recommender.predict(\n",
        "            user_id=user_id,\n",
        "            item_id=item_id,\n",
        "            similarity=similarity,\n",
        "            calculation_variety=calculation_variety,\n",
        "            k=second_k_value\n",
        "        )\n",
        "\n",
        "        # combine both with alpha as weight\n",
        "        combined_prediction = (self.alpha * collaborative_prediction) + ((1 - self.alpha) * content_based_prediction)\n",
        "        return combined_prediction"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "d160643fb14f6b77"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "id": "d160643fb14f6b77"
    },
    {
      "cell_type": "code",
      "id": "dfc14af51f24d030",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:04.118910Z",
          "start_time": "2025-06-13T15:46:04.092642Z"
        },
        "id": "dfc14af51f24d030"
      },
      "source": [
        "# Dataset class to handle user-item-rating data\n",
        "class RatingsDataset(Dataset):\n",
        "    def __init__(self, data: pd.DataFrame):\n",
        "        # Convert user, item, and rating columns to tensors\n",
        "        self.u = torch.tensor(data[\"user_idx\"].values, dtype=torch.long)\n",
        "        self.i = torch.tensor(data[\"item_idx\"].values, dtype=torch.long)\n",
        "        self.r = torch.tensor(data[\"rating\"].values, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        # Return the number of samples in the dataset\n",
        "        return len(self.r)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Return a single sample (user, item, rating) by index\n",
        "        return self.u[idx], self.i[idx], self.r[idx]\n",
        "\n",
        "\n",
        "# hybrid matrix factorization model\n",
        "class HybridMF(nn.Module):\n",
        "    def __init__(self, num_users: int, num_items: int, embedding_dim: int, item_features, dropout: float = 0.15):\n",
        "        super().__init__()\n",
        "        # Embedding layers for users and items (Embedding-layer is one layer in the neral network (vectors))\n",
        "        self.P = nn.Embedding(num_users, embedding_dim)\n",
        "        self.Q = nn.Embedding(num_items, embedding_dim)\n",
        "\n",
        "        # Bias terms for users and items (representate individual variances... e.g one user can generally give better ratings as default)\n",
        "        self.bu = nn.Embedding(num_users, 1)\n",
        "        self.bi = nn.Embedding(num_items, 1)\n",
        "\n",
        "        # Global bias term (reprentate the average variance over the complete dataset)\n",
        "        self.mu = nn.Parameter(torch.zeros(1))\n",
        "\n",
        "        # Linear layer to project item features into the latent space (to combine them with the embeddings of the items)\n",
        "        self.F = nn.Linear(item_features.shape[1], embedding_dim, bias=False)\n",
        "\n",
        "        # Register item features as a buffer (non-trainable parameter)\n",
        "        self.register_buffer(\"item_features\", item_features)\n",
        "\n",
        "        # Dropout layer for regularization\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "\n",
        "        # Initialize weights for embeddings and linear layer\n",
        "        nn.init.normal_(self.P.weight, std=0.05)\n",
        "        nn.init.normal_(self.Q.weight, std=0.05)\n",
        "        nn.init.xavier_uniform_(self.F.weight)\n",
        "\n",
        "    def forward(self, u, i):\n",
        "        # Compute item latent factors by combining embeddings and projected features\n",
        "        q = self.Q(i) + self.F(self.item_features[i])\n",
        "        q = self.drop(q)\n",
        "\n",
        "        # Compute the predicted rating\n",
        "        return (self.P(u) * q).sum(-1) + self.mu + self.bu(u).squeeze() + self.bi(i).squeeze()\n",
        "\n",
        "\n",
        "class DeepLearningRecommender:\n",
        "    def __init__(\n",
        "            self,\n",
        "            trainingdata: pd.DataFrame,\n",
        "            item_profile: pd.DataFrame,\n",
        "            testdata: pd.DataFrame,\n",
        "            embedding_dim=64,\n",
        "            batch_size=1024,\n",
        "            epochs=60,\n",
        "            lr=1e-3,\n",
        "            weight_decay=3e-5,\n",
        "            dropout_p=0.2,\n",
        "            early_stopping_rounds=10\n",
        "    ) -> None:\n",
        "\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.lr = lr  # learning rate\n",
        "        self.weight_decay = weight_decay\n",
        "        self.dropout_p = dropout_p\n",
        "        self.early_stopping_rounds = early_stopping_rounds\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "        # Prepare data and build the model\n",
        "        self.train_data, self.val_data, self.feat_mat, self.global_mean = self._prepare_data(trainingdata, item_profile, testdata)\n",
        "        self.model = self._build_model()\n",
        "        self.fit()\n",
        "\n",
        "    def _prepare_data(self, trainingdata, item_profile, testdata):\n",
        "        # Convert user and item ids to strings\n",
        "        trainingdata[[\"user_ID\", \"item_ID\"]] = trainingdata[[\"user_ID\", \"item_ID\"]].astype(str)\n",
        "        testdata[[\"user_ID\", \"item_ID\"]] = testdata[[\"user_ID\", \"item_ID\"]].astype(str)\n",
        "\n",
        "        # Create mappings from user/item ids to indices\n",
        "        self.user2idx = {u: i for i, u in enumerate(trainingdata[\"user_ID\"].unique())}\n",
        "        self.item2idx = {m: j for j, m in enumerate(trainingdata[\"item_ID\"].unique())}\n",
        "\n",
        "        # Map user and item ids to the indices in training and test data (both needed)\n",
        "        for df in [trainingdata, testdata]:\n",
        "            df[\"user_idx\"] = df[\"user_ID\"].map(self.user2idx)\n",
        "            df[\"item_idx\"] = df[\"item_ID\"].map(self.item2idx)\n",
        "\n",
        "        # filter and process item features\n",
        "        ip = item_profile[item_profile[\"item_ID\"].isin(self.item2idx)].copy()\n",
        "        ip[\"item_idx\"] = ip[\"item_ID\"].map(self.item2idx)\n",
        "        ip.sort_values(\"item_idx\", inplace=True)\n",
        "        feat_df = ip.filter(regex=\"^Genre_\")\n",
        "\n",
        "        # scale feature or set placeholder if no feature\n",
        "        if not feat_df.empty:\n",
        "            feat_df = StandardScaler().fit_transform(feat_df.fillna(0))\n",
        "        else:\n",
        "            feat_df = np.zeros((len(self.item2idx), 1))\n",
        "\n",
        "        # convert features to a tensor (array in a dimension you need, vgl. Skalar (5), Vektor ([1,2,3]), ...)\n",
        "        feat_mat = torch.tensor(feat_df, dtype=torch.float32)\n",
        "\n",
        "        # Compute the global mean rating... optional but whats the ase when user or item i unknown ? (vgl. cold-start-szenario)\n",
        "        global_mean = trainingdata[\"rating\"].mean()\n",
        "\n",
        "        # Create data loaders for training and validation (Dataloaders take the work of batching, shuffle or parallel loading to improve training)\n",
        "        train_loader = DataLoader(RatingsDataset(trainingdata), batch_size=self.batch_size, shuffle=True)\n",
        "        val_loader = DataLoader(RatingsDataset(testdata), batch_size=self.batch_size)\n",
        "\n",
        "        return train_loader, val_loader, feat_mat, global_mean\n",
        "\n",
        "    def _build_model(self):\n",
        "        # Build the hybrid matrix factorization model\n",
        "        return HybridMF(\n",
        "            num_users=len(self.train_data.dataset.u.unique()),\n",
        "            num_items=len(self.train_data.dataset.i.unique()),\n",
        "            embedding_dim=self.embedding_dim,\n",
        "            item_features=self.feat_mat,\n",
        "            dropout=self.dropout_p,\n",
        "        ).to(self.device)\n",
        "\n",
        "    def fit(self):\n",
        "        # Initialize optimizer and learning rate scheduler\n",
        "        opt = optim.Adam(self.model.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
        "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(opt, factor=0.5, patience=3)\n",
        "        best_mae, epochs_no_imp = float(\"inf\"), 0\n",
        "        best_model_state = None  # Variable to store the best model state\n",
        "\n",
        "        # Training loop ... as we discussed in the lecture\n",
        "        for ep in range(1, self.epochs + 1):\n",
        "            self.model.train()\n",
        "            epoch_loss = 0\n",
        "            for u, i, r in self.train_data:\n",
        "                u, i, r = u.to(self.device), i.to(self.device), r.to(self.device)\n",
        "                opt.zero_grad()\n",
        "                loss = nn.functional.smooth_l1_loss(self.model(u, i), r, beta=1.0)  # Feed-Forward\n",
        "                loss.backward()  # Backpropagation\n",
        "                opt.step()\n",
        "                epoch_loss += loss.item()  # collect the loss-value\n",
        "\n",
        "\n",
        "            # Calculate validation-Loss (we need the smallest MAE possible)\n",
        "            val_mae = self.evaluate_loader(self.val_data)\n",
        "            # Print average loss and MAE of each epoch\n",
        "            logger.debug(f\"Epoche {ep}\\t| Training Loss: {epoch_loss / len(self.train_data)} \\t| Validation MAE: {val_mae}\")\n",
        "            scheduler.step(val_mae)\n",
        "\n",
        "            # Save the best model\n",
        "            if val_mae < best_mae:\n",
        "                best_mae, epochs_no_imp = val_mae, 0\n",
        "                best_model_state = self.model.state_dict()\n",
        "            else:\n",
        "                epochs_no_imp += 1\n",
        "                if epochs_no_imp >= self.early_stopping_rounds:\n",
        "                    break\n",
        "\n",
        "        # Load the best model state from memory\n",
        "        if best_model_state is not None:\n",
        "            self.model.load_state_dict(best_model_state)\n",
        "\n",
        "\n",
        "    def evaluate_loader(self, loader):\n",
        "        # Evaluate the model on a data loader\n",
        "        self.model.eval()\n",
        "        err, n = 0.0, 0\n",
        "        with torch.no_grad():\n",
        "            for u, i, r in loader:\n",
        "                preds = self.model(u.to(self.device), i.to(self.device)).cpu()\n",
        "                err += torch.abs(preds - r).sum().item()\n",
        "                n += len(r)\n",
        "        return err / n\n",
        "\n",
        "    def predict(self, user_id, item_id):\n",
        "        # Convert user and item IDs to indices\n",
        "        user_idx = self.user2idx.get(user_id)\n",
        "        item_idx = self.item2idx.get(item_id)\n",
        "\n",
        "        # Handle cold-start cases\n",
        "        if user_idx is None and item_idx is None:\n",
        "            return float(self.global_mean)\n",
        "\n",
        "        if user_idx is None:\n",
        "            item_bias = self.model.bi.weight[item_idx].item()\n",
        "            return float(np.clip(self.global_mean + item_bias, 0.0, 5.0)) # clip ensures that the value is between 0 and 5\n",
        "\n",
        "        if item_idx is None:\n",
        "            user_bias = self.model.bu.weight[user_idx].item()\n",
        "            return float(np.clip(self.global_mean + user_bias, 0.0, 5.0)) # clip ensures that the value is between 0 and 5\n",
        "\n",
        "        # Compute the predicted rating\n",
        "        u = torch.tensor([user_idx], device=self.device)\n",
        "        i = torch.tensor([item_idx], device=self.device)\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            score = self.model(u, i).item()\n",
        "        return float(np.clip(score, 0.0, 5.0)) # clip ensures that the value is between 0 and 5\n",
        "\n",
        "\n",
        "\n",
        "class HyperparamOptimizedDeepLearningRecommender(Recommender):\n",
        "    def __init__(self, testdata: pd.DataFrame, item_profile: pd.DataFrame, trainingdata: pd.DataFrame, include_hyperparam_check: Optional[bool] = False):\n",
        "        super().__init__()\n",
        "        self.testdata = testdata\n",
        "        self.item_profile = item_profile\n",
        "        self.trainingdata = trainingdata\n",
        "\n",
        "        self.include_hyperparam_check= include_hyperparam_check\n",
        "        self.recommender = None\n",
        "\n",
        "\n",
        "    def _preprocess_data(self):\n",
        "        # this will be done in the used recommender class\n",
        "        pass\n",
        "\n",
        "    def _objective(self, trial):\n",
        "        embedding_dim = trial.suggest_int(\"embedding_dim\", 32, 128, step=16)\n",
        "        batch_size = trial.suggest_categorical(\"batch_size\", [16, 32, 64, 128])\n",
        "        lr = trial.suggest_loguniform(\"lr\", 1e-4, 1e-2)\n",
        "        dropout_p = trial.suggest_uniform(\"dropout_p\", 0.1, 0.5)\n",
        "        weight_decay = trial.suggest_loguniform(\"weight_decay\", 1e-6, 1e-3)\n",
        "\n",
        "        optimize_recommender = DeepLearningRecommender(\n",
        "            trainingdata=self.trainingdata,\n",
        "            item_profile=self.item_profile,\n",
        "            testdata=self.testdata,\n",
        "            embedding_dim=embedding_dim,\n",
        "            batch_size=batch_size,\n",
        "            lr=lr,\n",
        "            dropout_p=dropout_p,\n",
        "            weight_decay=weight_decay,\n",
        "        )\n",
        "\n",
        "        val_mae = optimize_recommender.evaluate_loader(optimize_recommender.val_data)\n",
        "        return val_mae\n",
        "\n",
        "    def _build_recommender(self, params: dict) -> None:\n",
        "        self.recommender = DeepLearningRecommender(\n",
        "            trainingdata=self.trainingdata,\n",
        "            item_profile=self.item_profile,\n",
        "            testdata=self.testdata,\n",
        "            embedding_dim=params[\"embedding_dim\"],\n",
        "            batch_size=params[\"batch_size\"],\n",
        "            lr=params[\"lr\"],\n",
        "            dropout_p=params[\"dropout_p\"],\n",
        "            weight_decay=params[\"weight_decay\"],\n",
        "        )\n",
        "\n",
        "    def _find_out_best_params(self) -> Dict[str, Any]:\n",
        "        study = optuna.create_study(direction=\"minimize\")\n",
        "        study.optimize(self._objective, n_trials=50)\n",
        "\n",
        "        print(\"Beste Parameter:\", study.best_params)\n",
        "\n",
        "        return study.best_params\n",
        "\n",
        "\n",
        "    def predict(\n",
        "            self,\n",
        "            user_id: str,\n",
        "            item_id: str,\n",
        "            similarity: Optional[Literal['cosine', 'pearson']] = 'cosine',\n",
        "            calculation_variety: Optional[Literal['weighted', 'unweighted']] = 'weighted',\n",
        "            k: Optional[int] = 3,\n",
        "            second_k_value: Optional[int] = None,\n",
        "    ) -> float:\n",
        "\n",
        "        if self.include_hyperparam_check:\n",
        "            best_params = self._find_out_best_params()\n",
        "        else:\n",
        "            # values came from our test with the hyperparam check\n",
        "            best_params = {\n",
        "                \"lr\": 0.00483293357554159,\n",
        "                \"embedding_dim\": 32,\n",
        "                \"dropout_p\": 0.24090306736140638,\n",
        "                \"weight_decay\": 0.00022232253823222672,\n",
        "                \"batch_size\": 64,\n",
        "            }\n",
        "\n",
        "\n",
        "        if self.recommender is None:\n",
        "            self._build_recommender(best_params)\n",
        "\n",
        "        return self.recommender.predict(user_id, item_id)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "333ff78ed02f42f6"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "id": "333ff78ed02f42f6"
    },
    {
      "cell_type": "markdown",
      "id": "f36958e4",
      "metadata": {
        "id": "f36958e4"
      },
      "source": [
        "## MAE Tester\n",
        "Verwendet, um die verschiedenen Recommender zu Evaluieren und anhand des MAEs zu vergleichen"
      ]
    },
    {
      "cell_type": "code",
      "id": "bd623ba6223a9825",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:04.157911Z",
          "start_time": "2025-06-13T15:46:04.132301Z"
        },
        "id": "bd623ba6223a9825"
      },
      "source": [
        "class Test(BaseModel):\n",
        "    name: str\n",
        "    type: Literal[\"collaborative_filtering\", \"content_based\", \"hybrid\", \"deep_learning\"]\n",
        "    mode: Optional[Literal[\"user\", \"item\"]] = \"item\"\n",
        "    k_value: Optional[int] = 3\n",
        "    second_k_value: Optional[int] = 3\n",
        "    metric: Optional[Literal[\"cosine\", \"pearson\"]] = 'cosine'\n",
        "    calculation_variety: Optional[Literal[\"weighted\", \"unweighted\"]] = 'weighted'\n",
        "    alpha: Optional[float] = 0.5\n",
        "\n",
        "\n",
        "class TestResult(BaseModel):\n",
        "    name: str\n",
        "    type: Literal[\"collaborative_filtering\", \"content_based\", \"hybrid\", \"deep_learning\"]\n",
        "    mode: Literal[\"user\", \"item\"] | None\n",
        "    k_value: int | None\n",
        "    second_k_value: int | None\n",
        "    metric: Literal[\"cosine\", \"pearson\"] | None\n",
        "    calculation_variety: Literal[\"weighted\", \"unweighted\"] | None\n",
        "    alpha: float | None\n",
        "    mae: float\n",
        "\n",
        "\n",
        "class TestResults(BaseModel): # just for saving in a \"pretty\" form\n",
        "    date: str\n",
        "    num_tests: int\n",
        "    best_test: TestResult\n",
        "    results: List[TestResult]\n",
        "\n",
        "\n",
        "\n",
        "class MAETester:\n",
        "    def __init__(self, tests: List[Test], test_data_path: str, data_path: str, item_profile_path: str, ratings: str, eval_data_path: str):\n",
        "        self.tests = tests\n",
        "        self.testdata = pd.read_csv(test_data_path)  # testdata (for training of Neural Network)\n",
        "        self.item_profile = pd.read_csv(item_profile_path)\n",
        "        self.user_ratings = pd.read_csv(ratings)\n",
        "        self.eval_data = pd.read_csv(eval_data_path)  # eval / testdata for MAE tester\n",
        "        self._prepare_data()\n",
        "        self.data = pd.read_csv(data_path)  # trainings-data\n",
        "        self.results: List[TestResult] = []\n",
        "\n",
        "\n",
        "    def _prepare_data(self):\n",
        "        self.eval_data[\"user_ID\"] = self.eval_data[\"user_ID\"].astype(str)\n",
        "        self.eval_data[\"item_ID\"] = self.eval_data[\"item_ID\"].astype(str)\n",
        "\n",
        "    # because we only have 0.5 steps in testdata\n",
        "    @staticmethod\n",
        "    def _round_to_nearest_half(value: float):\n",
        "        return round(value * 2) / 2\n",
        "\n",
        "    def run_tests(self) -> pd.DataFrame:\n",
        "        for test in self.tests:\n",
        "            result = self._run_test(test)\n",
        "            self.results.append(result)\n",
        "            logger.success(f\"Test abgeschlossen: {test.name}, MAE: {result.mae:.4f}\\n\")\n",
        "\n",
        "        # display final resultse\n",
        "        result_df = self._summarize_test_results()\n",
        "\n",
        "        return result_df\n",
        "\n",
        "    def _run_test(self, test: Test) -> TestResult:\n",
        "        logger.info(f\"Running test: {test.name}\")\n",
        "\n",
        "        if test.type == \"content_based\":\n",
        "            recommender = ContentBasedRecommender(\n",
        "                item_profile=self.item_profile,\n",
        "                user_ratings=self.user_ratings,\n",
        "            )\n",
        "        elif test.type == \"collaborative_filtering\":\n",
        "            recommender = CollaborativeFilteringRecommender(\n",
        "                mode=test.mode, # ignore type (that this can be NONE)\n",
        "                data=self.data,\n",
        "            )\n",
        "        elif test.type == \"hybrid\":\n",
        "            recommender = HybridRecommender(\n",
        "                data=self.data,\n",
        "                item_profile=self.item_profile,\n",
        "                user_ratings=self.user_ratings,\n",
        "                mode=test.mode,  # ignore type (that this can be NONE)\n",
        "                alpha=test.alpha,\n",
        "            )\n",
        "        elif test.type == \"deep_learning\":\n",
        "            recommender = HyperparamOptimizedDeepLearningRecommender(\n",
        "                trainingdata=self.user_ratings,\n",
        "                item_profile=self.item_profile,\n",
        "                testdata=self.testdata,\n",
        "            )\n",
        "        else:\n",
        "            raise ValueError(f\"Unbekannter Recomendertyp: {test.type}\")\n",
        "\n",
        "        predictions = []\n",
        "        actuals = []\n",
        "\n",
        "        eval_data_list = self.eval_data.to_numpy()\n",
        "\n",
        "        for row in tqdm(eval_data_list, desc=\"Vorhersagen werden berechnet\"):\n",
        "            user_id: str = str(row[0])\n",
        "            item_id: str = str(row[1])\n",
        "            actual_rating = row[2]\n",
        "\n",
        "            try:\n",
        "                predicted_rating = recommender.predict(\n",
        "                    user_id=user_id,\n",
        "                    item_id=item_id,\n",
        "                    similarity=test.metric,\n",
        "                    calculation_variety=test.calculation_variety,\n",
        "                    k=test.k_value,\n",
        "                    second_k_value=test.second_k_value,\n",
        "                )\n",
        "\n",
        "                predicted_rating = self._round_to_nearest_half(value=predicted_rating)\n",
        "\n",
        "                predictions.append(predicted_rating)\n",
        "                actuals.append(actual_rating)\n",
        "            except ValueError as e:\n",
        "                logger.warning(f\"Fehler bei der Vorhersage: {e}\")\n",
        "\n",
        "        mae = self._mean_absolute_error(actuals, predictions)\n",
        "\n",
        "        return TestResult(\n",
        "            name=test.name,\n",
        "            type=test.type,\n",
        "            mode=test.mode,\n",
        "            k_value=test.k_value,\n",
        "            metric=test.metric,\n",
        "            calculation_variety=test.calculation_variety,\n",
        "            alpha=test.alpha,\n",
        "            second_k_value=test.second_k_value,\n",
        "            mae=mae,\n",
        "        )\n",
        "\n",
        "    @staticmethod\n",
        "    def _mean_absolute_error(actuals: List[float], predictions: List[float]) -> float:\n",
        "        if not actuals or not predictions or len(actuals) != len(predictions):\n",
        "            raise ValueError(\"Listen fÃ¼r tatsÃ¤chliche und vorhergesagte Werte mÃ¼ssen gleich lang und nicht leer sein.\")\n",
        "\n",
        "        absolute_errors = [abs(a - p) for a, p in zip(actuals, predictions)]\n",
        "        mae = sum(absolute_errors) / len(absolute_errors)\n",
        "        return mae\n",
        "\n",
        "    def _summarize_test_results(self) -> pd.DataFrame:\n",
        "        if not self.results:\n",
        "            logger.info(\"Keine Testergebnisse vorhanden.\")\n",
        "            return\n",
        "\n",
        "        summary_df = pd.DataFrame([{\n",
        "            \"Testname\": result.name,\n",
        "            \"Recomendertyp\": result.type,\n",
        "            \"Modus\": result.mode if result.type == \"collaborative_filtering\" else \"/\",\n",
        "            \"k-Wert\": \"/\" if result.type == \"deep_learning\" else result.k_value,\n",
        "            \"Metrik\": result.metric if result.type == \"collaborative_filtering\" else \"/\",\n",
        "            \"Berechnungsvariante\": result.calculation_variety if result.type == \"collaborative_filtering\" else \"/\",\n",
        "            \"Alpha (weight)\": result.alpha if result.type == \"hybrid\" else \"/\",\n",
        "            \"MAE\": result.mae\n",
        "        } for result in self.results])\n",
        "\n",
        "        print(\"-\" * 50)\n",
        "        print(\"Zusammenfassung der Testergebnisse:\")\n",
        "        print(summary_df.to_string(index=False))\n",
        "        print(\"-\" * 50)\n",
        "\n",
        "        return summary_df\n"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "d924f474e12c71d9",
      "metadata": {
        "id": "d924f474e12c71d9"
      },
      "source": [
        "# Beginn der Aufrufe und Nutzung der Recommender"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6af79d55b715866d",
      "metadata": {
        "id": "6af79d55b715866d"
      },
      "source": [
        "Wir haben viele TestfÃ¤lle durchgefÃ¼hrt und uns sowohl mit dem klassischen Collaborative Filtering (User- & Itembased) sowie Content-Based Filtering beschÃ¤ftigt. AnschlieÃŸend wurden beide Methoden kombiniert in einem Hybriden Recommender. Dieser Ansatz verbesserte den MAE minimal weshalb wir uns noch mit einem Deep-Learning Recommender beschÃ¤ftigten.\n",
        "\n",
        "---\n",
        "\n",
        "Der Deep-Learning Recommender performte besser, jedoch aufgrund der geringen Datenmenge nach wie vor nicht perfekt. ZusÃ¤tzlich zum besten MAE liefert der Deep-Learning Recommender den Vorteil, nach einmaligem Training schnell Empfehlungen liefern zu kÃ¶nnen."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4593c5f25d4441af",
      "metadata": {
        "id": "4593c5f25d4441af"
      },
      "source": [
        "Um diesen Recommender zu testen stellen wir eine struktur bereit wobei lediglich der parameter `testdata` angepasst werden muss um den evaluationsdatensatz zu verwenden. *(zu sehen etwas weiter unten)*"
      ]
    },
    {
      "cell_type": "code",
      "id": "3b9bbc3845fde0ce",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:04.181120Z",
          "start_time": "2025-06-13T15:46:04.177183Z"
        },
        "id": "3b9bbc3845fde0ce"
      },
      "source": [
        "choosen_recommender_profile = [\n",
        "    Test(name=\"ChoosenDeepLearning\", type=\"deep_learning\")\n",
        "]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "758ad31df10683b8"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "id": "758ad31df10683b8"
    },
    {
      "metadata": {
        "id": "649e17ae98cdff8f"
      },
      "cell_type": "markdown",
      "source": [
        "#### Optionale (andere) Testprofile die verwendet wurden und vollstÃ¤ndigkeitshalber hier aufgefÃ¼hrt sind"
      ],
      "id": "649e17ae98cdff8f"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:04.207854Z",
          "start_time": "2025-06-13T15:46:04.200287Z"
        },
        "id": "588826d545fb7fef"
      },
      "cell_type": "code",
      "source": [
        "collaborative_filtering_profiles = [\n",
        "    Test(name=\"UserBased_1_cosine\", type=\"collaborative_filtering\", mode=\"user\", k_value=4, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
        "    Test(name=\"UserBased_2_cosine\", type=\"collaborative_filtering\", mode=\"user\", k_value=3, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
        "    Test(name=\"UserBased_3_cosine\", type=\"collaborative_filtering\", mode=\"user\", k_value=4, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
        "    Test(name=\"UserBased_4_cosine\", type=\"collaborative_filtering\", mode=\"user\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
        "\n",
        "    Test(name=\"ItemBased_1_cosine\", type=\"collaborative_filtering\", mode=\"item\", k_value=4, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
        "    Test(name=\"ItemBased_2_cosine\", type=\"collaborative_filtering\", mode=\"item\", k_value=3, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
        "    Test(name=\"ItemBased_3_cosine\", type=\"collaborative_filtering\", mode=\"item\", k_value=4, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
        "    Test(name=\"ItemBased_4_cosine\", type=\"collaborative_filtering\", mode=\"item\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\"),\n",
        "\n",
        "    Test(name=\"UserBased_1_pearson\", type=\"collaborative_filtering\", mode=\"user\", k_value=4, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
        "    Test(name=\"UserBased_2_pearson\", type=\"collaborative_filtering\", mode=\"user\", k_value=3, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
        "    Test(name=\"UserBased_3_pearson\", type=\"collaborative_filtering\", mode=\"user\", k_value=4, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
        "    Test(name=\"UserBased_4_pearson\", type=\"collaborative_filtering\", mode=\"user\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
        "\n",
        "    Test(name=\"ItemBased_1_pearson\", type=\"collaborative_filtering\", mode=\"item\", k_value=4, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
        "    Test(name=\"ItemBased_2_pearson\", type=\"collaborative_filtering\", mode=\"item\", k_value=3, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
        "    Test(name=\"ItemBased_3_pearson\", type=\"collaborative_filtering\", mode=\"item\", k_value=4, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
        "    Test(name=\"ItemBased_4_pearson\", type=\"collaborative_filtering\", mode=\"item\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\"),\n",
        "]"
      ],
      "id": "588826d545fb7fef",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:04.232889Z",
          "start_time": "2025-06-13T15:46:04.227318Z"
        },
        "id": "d1df2dc28368aa35"
      },
      "cell_type": "code",
      "source": [
        "content_based_profiles = [\n",
        "    Test(name=\"ContentBased_1\", type=\"content_based\", k_value=3),\n",
        "    Test(name=\"ContentBased_2\", type=\"content_based\", k_value=4),\n",
        "    Test(name=\"ContentBased_3\", type=\"content_based\", k_value=5),\n",
        "    Test(name=\"ContentBased_4\", type=\"content_based\", k_value=6),\n",
        "    Test(name=\"ContentBased_5\", type=\"content_based\", k_value=7),\n",
        "    Test(name=\"ContentBased_6\", type=\"content_based\", k_value=8),\n",
        "    Test(name=\"ContentBased_7\", type=\"content_based\", k_value=9),\n",
        "    Test(name=\"ContentBased_8\", type=\"content_based\", k_value=10),\n",
        "    Test(name=\"ContentBased_9\", type=\"content_based\", k_value=11),\n",
        "    Test(name=\"ContentBased_10\", type=\"content_based\", k_value=12),\n",
        "    Test(name=\"ContentBased_11\", type=\"content_based\", k_value=13),\n",
        "    Test(name=\"ContentBased_12\", type=\"content_based\", k_value=14),\n",
        "]"
      ],
      "id": "d1df2dc28368aa35",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:04.306244Z",
          "start_time": "2025-06-13T15:46:04.298273Z"
        },
        "id": "90d35683f5188ea9"
      },
      "cell_type": "code",
      "source": [
        "hybrid_profiles = [\n",
        "    Test(name=\"Hybrid_1\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.5),\n",
        "    Test(name=\"Hybrid_2\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.75),\n",
        "    Test(name=\"Hybrid_3\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.25),\n",
        "\n",
        "    Test(name=\"Hybrid_4\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.5),\n",
        "    Test(name=\"Hybrid_5\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.75),\n",
        "    Test(name=\"Hybrid_6\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"cosine\", calculation_variety=\"weighted\", alpha=0.25),\n",
        "\n",
        "    Test(name=\"Hybrid_7\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.5),\n",
        "    Test(name=\"Hybrid_8\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.75),\n",
        "    Test(name=\"Hybrid_9\", type=\"hybrid\", mode=\"user\", k_value=5, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.25),\n",
        "\n",
        "    Test(name=\"Hybrid_10\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.5),\n",
        "    Test(name=\"Hybrid_11\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.75),\n",
        "    Test(name=\"Hybrid_12\", type=\"hybrid\", mode=\"user\", k_value=5, second_k_value=14, metric=\"pearson\", calculation_variety=\"weighted\", alpha=0.25),\n",
        "\n",
        "]"
      ],
      "id": "90d35683f5188ea9",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "c3de1e9f7ef06c96"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "id": "c3de1e9f7ef06c96"
    },
    {
      "metadata": {
        "id": "dab2f1ae84c66fb6"
      },
      "cell_type": "markdown",
      "source": [
        "## Aufruf des MAE Testers\n",
        "Dem Tester werden die entscheidenden Daten Ã¼bergeben und anschlieÃŸend wird der MAE fÃ¼r die ausgewÃ¤hlten / Ã¼bergebenene Test-Profile ermittelt"
      ],
      "id": "dab2f1ae84c66fb6"
    },
    {
      "cell_type": "code",
      "source": [
        "#csv-Datei einlesen\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 38
        },
        "id": "aREwQytc_zd-",
        "outputId": "bc0fd168-42ef-4566-9901-484fb549a758"
      },
      "id": "aREwQytc_zd-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-0e07376b-e3d5-457e-9bd9-2a30c6bfcdfe\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-0e07376b-e3d5-457e-9bd9-2a30c6bfcdfe\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:04.331060Z",
          "start_time": "2025-06-13T15:46:04.327355Z"
        },
        "id": "ff1a9deee9507f5b"
      },
      "cell_type": "code",
      "source": [
        "eval_data_path = \"Testdaten_FlixNet.csv\"   # TODO: change to use another Eval-Dataset"
      ],
      "id": "ff1a9deee9507f5b",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "1a177fda3e3854fd",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:04.419756Z",
          "start_time": "2025-06-13T15:46:04.353898Z"
        },
        "id": "1a177fda3e3854fd"
      },
      "source": [
        "tester = MAETester(\n",
        "        tests=choosen_recommender_profile,\n",
        "        test_data_path=\"Testdaten_FlixNet.csv\",  # also used for the \"test/training for neral network\"\n",
        "        eval_data_path=eval_data_path,  # TODO: Here you need to set your path\n",
        "        data_path=\"Bewertungsmatrix_FlixNet.csv\",\n",
        "        ratings=\"Ratings_FlixNet.csv\",\n",
        "        item_profile_path=\"Itemprofile_FlixNet.csv\",\n",
        "    )"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "1259e7059201639c",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-06-13T15:46:15.577927Z",
          "start_time": "2025-06-13T15:46:04.434844Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 733
        },
        "id": "1259e7059201639c",
        "outputId": "29164e3f-b7d9-4a82-b033-e49fd79299f7"
      },
      "source": [
        "1 result = tester.run_tests()\n",
        "result # print result here as dataframe\n",
        "result = tester.run_tests()\n",
        "result # print result here as dataframe"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2025-06-16 13:23:37.906\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m_run_test\u001b[0m:\u001b[36m65\u001b[0m - \u001b[1mRunning test: ChoosenDeepLearning\u001b[0m\n",
            "Vorhersagen werden berechnet:   0%|          | 0/1595 [00:00<?, ?it/s]\u001b[32m2025-06-16 13:23:38.730\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 1\t| Training Loss: 2.077234741597801 \t| Validation MAE: 1.7166857776223305\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:39.436\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 2\t| Training Loss: 0.6823071730907425 \t| Validation MAE: 0.8501930045483628\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:40.175\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 3\t| Training Loss: 0.4008083528212268 \t| Validation MAE: 0.794121946137527\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:40.975\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 4\t| Training Loss: 0.35764197563263855 \t| Validation MAE: 0.7651278887422854\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:41.716\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 5\t| Training Loss: 0.32481469749384506 \t| Validation MAE: 0.7462227082925157\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:42.472\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 6\t| Training Loss: 0.3015422620474159 \t| Validation MAE: 0.7215714625056634\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:43.203\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 7\t| Training Loss: 0.28061953725243705 \t| Validation MAE: 0.7104448372293789\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:43.968\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 8\t| Training Loss: 0.2641427518637008 \t| Validation MAE: 0.699710781372453\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:44.722\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 9\t| Training Loss: 0.24829582946495413 \t| Validation MAE: 0.6920454665037532\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:45.404\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 10\t| Training Loss: 0.23793352403794857 \t| Validation MAE: 0.6864084441086341\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:46.208\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 11\t| Training Loss: 0.22617312279944185 \t| Validation MAE: 0.6843348942580267\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:46.994\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 12\t| Training Loss: 0.21929514969029806 \t| Validation MAE: 0.678990637321831\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:47.744\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 13\t| Training Loss: 0.21118104857297 \t| Validation MAE: 0.6786048889160157\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:48.728\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 14\t| Training Loss: 0.2062920168778742 \t| Validation MAE: 0.6758328285336869\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:49.823\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 15\t| Training Loss: 0.20036560815436757 \t| Validation MAE: 0.6743779986629665\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:50.863\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 16\t| Training Loss: 0.1971170421222317 \t| Validation MAE: 0.6745737344867383\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:51.681\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 17\t| Training Loss: 0.19399507714881642 \t| Validation MAE: 0.6744999852673761\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:52.452\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 18\t| Training Loss: 0.19231108655381113 \t| Validation MAE: 0.6752451642553634\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:53.167\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 19\t| Training Loss: 0.1885435585173364 \t| Validation MAE: 0.6763800952875502\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:53.904\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 20\t| Training Loss: 0.17417172455855648 \t| Validation MAE: 0.6761760412712456\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:54.657\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 21\t| Training Loss: 0.17093343956275583 \t| Validation MAE: 0.6755368486840897\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:55.394\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 22\t| Training Loss: 0.16967429370821202 \t| Validation MAE: 0.6754824790835007\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:56.120\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 23\t| Training Loss: 0.16705767949157796 \t| Validation MAE: 0.6755889055497221\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:56.875\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 24\t| Training Loss: 0.1594307472497338 \t| Validation MAE: 0.6753123029272384\u001b[0m\n",
            "\u001b[32m2025-06-16 13:23:57.578\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mfit\u001b[0m:\u001b[36m156\u001b[0m - \u001b[34m\u001b[1mEpoche 25\t| Training Loss: 0.15871202064670992 \t| Validation MAE: 0.6757097082825664\u001b[0m\n",
            "Vorhersagen werden berechnet: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1595/1595 [00:20<00:00, 79.30it/s] \n",
            "\u001b[32m2025-06-16 13:23:58.028\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mrun_tests\u001b[0m:\u001b[36m57\u001b[0m - \u001b[32m\u001b[1mTest abgeschlossen: ChoosenDeepLearning, MAE: 0.6630\n",
            "\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------\n",
            "Zusammenfassung der Testergebnisse:\n",
            "           Testname Recomendertyp Modus k-Wert Metrik Berechnungsvariante Alpha (weight)      MAE\n",
            "ChoosenDeepLearning deep_learning     /      /      /                   /              / 0.661129\n",
            "ChoosenDeepLearning deep_learning     /      /      /                   /              / 0.663009\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              Testname  Recomendertyp Modus k-Wert Metrik Berechnungsvariante  \\\n",
              "0  ChoosenDeepLearning  deep_learning     /      /      /                   /   \n",
              "1  ChoosenDeepLearning  deep_learning     /      /      /                   /   \n",
              "\n",
              "  Alpha (weight)       MAE  \n",
              "0              /  0.661129  \n",
              "1              /  0.663009  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32b83fce-532a-4a74-adcd-e736d2d513ba\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Testname</th>\n",
              "      <th>Recomendertyp</th>\n",
              "      <th>Modus</th>\n",
              "      <th>k-Wert</th>\n",
              "      <th>Metrik</th>\n",
              "      <th>Berechnungsvariante</th>\n",
              "      <th>Alpha (weight)</th>\n",
              "      <th>MAE</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ChoosenDeepLearning</td>\n",
              "      <td>deep_learning</td>\n",
              "      <td>/</td>\n",
              "      <td>/</td>\n",
              "      <td>/</td>\n",
              "      <td>/</td>\n",
              "      <td>/</td>\n",
              "      <td>0.661129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ChoosenDeepLearning</td>\n",
              "      <td>deep_learning</td>\n",
              "      <td>/</td>\n",
              "      <td>/</td>\n",
              "      <td>/</td>\n",
              "      <td>/</td>\n",
              "      <td>/</td>\n",
              "      <td>0.663009</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32b83fce-532a-4a74-adcd-e736d2d513ba')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32b83fce-532a-4a74-adcd-e736d2d513ba button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32b83fce-532a-4a74-adcd-e736d2d513ba');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d5bce49f-600b-48e6-b542-dca30769b925\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d5bce49f-600b-48e6-b542-dca30769b925')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d5bce49f-600b-48e6-b542-dca30769b925 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_797f5fe6-5204-4c3c-a12b-c8ed82c7504e\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('result')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_797f5fe6-5204-4c3c-a12b-c8ed82c7504e button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('result');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result",
              "summary": "{\n  \"name\": \"result\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"Testname\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"ChoosenDeepLearning\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recomendertyp\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"deep_learning\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Modus\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"k-Wert\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Metrik\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Berechnungsvariante\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Alpha (weight)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"/\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MAE\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0013299814066204255,\n        \"min\": 0.661128526645768,\n        \"max\": 0.6630094043887147,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.6630094043887147\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ergebnis aller Testcases (ohne DeepLearning)"
      ],
      "metadata": {
        "id": "Wv4pvaQlBuHE"
      },
      "id": "Wv4pvaQlBuHE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Testname              | Recomendertyp           | Modus                  | k-Wert | Metrik  | Berechnungsvariante | Alpha (weight) | MAE      |\n",
        "|-----------------------|--------------------------|-------------------------|--------|---------|----------------------|----------------|----------|\n",
        "| UserBased_1_cosine    | collaborative_filtering | user                   | 2      | cosine  | weighted             | /              | 0.870846 |\n",
        "| UserBased_2_cosine    | collaborative_filtering | user                   | 3      | cosine  | weighted             | /              | 0.815674 |\n",
        "| UserBased_3_cosine    | collaborative_filtering | user                   | 4      | cosine  | weighted             | /              | 0.785266 |\n",
        "| UserBased_4_cosine    | collaborative_filtering | user                   | 5      | cosine  | weighted             | /              | 0.774922 |\n",
        "| ItemBased_1_cosine    | collaborative_filtering | item                   | 2      | cosine  | weighted             | /              | 0.933542 |\n",
        "| ItemBased_2_cosine    | collaborative_filtering | item                   | 3      | cosine  | weighted             | /              | 0.884013 |\n",
        "| ItemBased_3_cosine    | collaborative_filtering | item                   | 4      | cosine  | weighted             | /              | 0.855799 |\n",
        "| ItemBased_4_cosine    | collaborative_filtering | item                   | 5      | cosine  | weighted             | /              | 0.841066 |\n",
        "| UserBased_1_pearson   | collaborative_filtering | user                   | 2      | pearson | weighted             | /              | 0.865831 |\n",
        "| UserBased_2_pearson   | collaborative_filtering | user                   | 3      | pearson | weighted             | /              | 0.805956 |\n",
        "| UserBased_3_pearson   | collaborative_filtering | user                   | 4      | pearson | weighted             | /              | 0.781505 |\n",
        "| UserBased_4_pearson   | collaborative_filtering | user                   | 5      | pearson | weighted             | /              | 0.771473 |\n",
        "| ItemBased_1_pearson   | collaborative_filtering | item                   | 2      | pearson | weighted             | /              | 0.927273 |\n",
        "| ItemBased_2_pearson   | collaborative_filtering | item                   | 3      | pearson | weighted             | /              | 0.873981 |\n",
        "| ItemBased_3_pearson   | collaborative_filtering | item                   | 4      | pearson | weighted             | /              | 0.847022 |\n",
        "| ItemBased_4_pearson   | collaborative_filtering | item                   | 5      | pearson | weighted             | /              | 0.825078 |\n",
        "| ContentBased_1        | content_based           | /                      | 3      | /       | /                    | /              | 0.878683 |\n",
        "| ContentBased_2        | content_based           | /                      | 4      | /       | /                    | /              | 0.839812 |\n",
        "| ContentBased_3        | content_based           | /                      | 5      | /       | /                    | /              | 0.822571 |\n",
        "| ContentBased_4        | content_based           | /                      | 6      | /       | /                    | /              | 0.830721 |\n",
        "| ContentBased_5        | content_based           | /                      | 7      | /       | /                    | /              | 0.827273 |\n",
        "| ContentBased_6        | content_based           | /                      | 8      | /       | /                    | /              | 0.816928 |\n",
        "| ContentBased_7        | content_based           | /                      | 9      | /       | /                    | /              | 0.813166 |\n",
        "| ContentBased_8        | content_based           | /                      | 10     | /       | /                    | /              | 0.813793 |\n",
        "| ContentBased_9        | content_based           | /                      | 11     | /       | /                    | /              | 0.815047 |\n",
        "| ContentBased_10       | content_based           | /                      | 12     | /       | /                    | /              | 0.800313 |\n",
        "| ContentBased_11       | content_based           | /                      | 13     | /       | /                    | /              | 0.803448 |\n",
        "| ContentBased_12       | content_based           | /                      | 14     | /       | /                    | /              | 0.802821 |\n",
        "| Hybrid_1              | hybrid                  | /                      | 5      | /       | /                    | 0.5            | 0.739812 |\n",
        "| Hybrid_2              | hybrid                  | /                      | 5      | /       | /                    | 0.75           | 0.743887 |\n",
        "| Hybrid_3              | hybrid                  | /                      | 5      | /       | /                    | 0.25           | 0.786834 |\n",
        "| Hybrid_4              | hybrid                  | /                      | 5      | /       | /                    | 0.5            | 0.720376 |\n",
        "| Hybrid_5              | hybrid                  | /                      | 5      | /       | /                    | 0.75           | 0.737304 |\n",
        "| Hybrid_6              | hybrid                  | /                      | 5      | /       | /                    | 0.25           | 0.741379 |\n",
        "| Hybrid_7              | hybrid                  | /                      | 5      | /       | /                    | 0.5            | 0.741379 |\n",
        "| Hybrid_8              | hybrid                  | /                      | 5      | /       | /                    | 0.75           | 0.742006 |\n",
        "| Hybrid_9              | hybrid                  | /                      | 5      | /       | /                    | 0.25           | 0.787147 |\n",
        "| Hybrid_10             | hybrid                  | /                      | 5      | /       | /                    | 0.5            | 0.720376 |\n",
        "| Hybrid_11             | hybrid                  | /                      | 5      | /       | /                    | 0.75           | 0.735110 |\n",
        "| Hybrid_12             | hybrid                  | /                      | 5      | /       | /                    | 0.25           | 0.740125 |\n"
      ],
      "metadata": {
        "id": "uOUW6ZTqBpjv"
      },
      "id": "uOUW6ZTqBpjv"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}